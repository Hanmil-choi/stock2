import streamlit as st
# --- Safe initialization for `custom_indicator_expr` ---
if 'custom_indicator_expr' not in globals():
    custom_indicator_expr = ""
# --------------------------------------------------------

import pandas as pd
import os
from glob import glob
import datetime as dt
import numpy as np

def find_column(df, target_names):
    for col in df.columns:
        if col.strip().lower() in [name.lower() for name in target_names]:
            return col
    return None

def calculate_returns(df, date_col, close_col):
    """ìƒìŠ¹ë¥ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col])
    df = df.sort_values(date_col)
    
    # 2ì¼, 20ì¼, 60ì¼ ìƒìŠ¹ë¥  ê³„ì‚°
    df['return_2d'] = df[close_col].pct_change(2) * 100
    df['return_20d'] = df[close_col].pct_change(20) * 100
    df['return_60d'] = df[close_col].pct_change(60) * 100
    
    return df

def calculate_relative_momentum(df_stock, df_benchmark, date_col, close_col, periods=[20, 60, 120]):
    """KODEX 200ì— ëŒ€í•œ ìƒëŒ€ ëª¨ë©˜í…€ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df_stock.copy()
    df_bm = df_benchmark.copy()
    
    # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸°
    bm_date_col = find_column(df_bm, ['ê±°ë˜ì¼ì', 'date', 'Date', 'ë‚ ì§œ'])
    bm_close_col = find_column(df_bm, ['ì¢…ê°€', 'close', 'Close', 'ì¢…ê°€'])
    
    # ë‚ ì§œ í˜•ì‹ í†µì¼ (YYYYMMDD í˜•ì‹ìœ¼ë¡œ íŒŒì‹±)
    df[date_col] = pd.to_datetime(df[date_col], format='%Y%m%d')
    df_bm[bm_date_col] = pd.to_datetime(df_bm[bm_date_col], format='%Y%m%d')
    
    # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
    merged = pd.merge(
        df[[date_col, close_col]], 
        df_bm[[bm_date_col, bm_close_col]].rename(columns={bm_date_col: date_col, bm_close_col: "bm_close"}), 
        on=date_col, 
        how="inner"
    )
    
    # ê° ê¸°ê°„ë³„ ìƒëŒ€ ëª¨ë©˜í…€ ê³„ì‚°
    for period in periods:
        merged[f"rel_mom_{period}"] = (
            (merged[close_col] / merged[close_col].shift(period)) /
            (merged["bm_close"] / merged["bm_close"].shift(period)) - 1
        ) * 100  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
    
    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì— ìƒëŒ€ ëª¨ë©˜í…€ ì»¬ëŸ¼ ì¶”ê°€ (ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘)
    result_df = df.copy()
    for period in periods:
        # ë‚ ì§œë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ë§¤í•‘
        merged_subset = merged[[date_col, f"rel_mom_{period}"]].set_index(date_col)
        result_df[f"rel_mom_{period}"] = result_df[date_col].map(merged_subset[f"rel_mom_{period}"])
    
    return result_df

def calculate_52week_high_low(df, date_col, close_col, high_col, low_col):
    """52ì£¼ ê³ ì /ì €ì ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col])
    df = df.sort_values(date_col)
    
    # 52ì£¼(ì•½ 252ê±°ë˜ì¼) ê³ ì /ì €ì  ê³„ì‚°
    df['high_52w'] = df[high_col].rolling(window=252, min_periods=1).max()
    df['low_52w'] = df[low_col].rolling(window=252, min_periods=1).min()
    
    # í˜„ì¬ê°€ ëŒ€ë¹„ 52ì£¼ ê³ ì /ì €ì  ë¹„ìœ¨
    df['high_52w_ratio'] = (df[close_col] / df['high_52w']) * 100
    df['low_52w_ratio'] = (df[close_col] / df['low_52w']) * 100
    
    return df

def calculate_sma(df, close_col, periods=[5, 10, 20, 60, 120]):
    """ë‹¨ìˆœì´ë™í‰ê· ì„ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    for period in periods:
        df[f'sma{period}'] = df[close_col].rolling(window=period, min_periods=1).mean()
    return df
    
def calculate_ema(df, close_col, periods=[12, 26]):
    """ì§€ìˆ˜ì´ë™í‰ê· ì„ ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    for period in periods:
        df[f'ema{period}'] = df[close_col].ewm(span=period, adjust=False).mean()
    return df

def calculate_rsi(df, close_col, period=14):
    """RSIë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    delta = df[close_col].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    return df

def calculate_macd(df, close_col, fast=12, slow=26, signal=9):
    """MACDë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    ema_fast = df[close_col].ewm(span=fast, adjust=False).mean()
    ema_slow = df[close_col].ewm(span=slow, adjust=False).mean()
    df['macd'] = ema_fast - ema_slow
    df['macd_signal'] = df['macd'].ewm(span=signal, adjust=False).mean()
    df['macd_histogram'] = df['macd'] - df['macd_signal']
    return df

def calculate_volume_indicators(df, volume_col, close_col):
    """ê±°ë˜ëŸ‰ ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    
    # ê±°ë˜ëŸ‰ ì´ë™í‰ê· 
    df['volume_sma5'] = df[volume_col].rolling(window=5, min_periods=1).mean()
    df['volume_sma20'] = df[volume_col].rolling(window=20, min_periods=1).mean()
    
    # ê±°ë˜ëŸ‰ ë¹„ìœ¨ (í˜„ì¬ ê±°ë˜ëŸ‰ / 20ì¼ í‰ê·  ê±°ë˜ëŸ‰)
    df['volume_ratio'] = df[volume_col] / df['volume_sma20']
    
    return df

def calculate_bollinger_bands(df, close_col, period=20, std_dev=2):
    """ë³¼ë¦°ì € ë°´ë“œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    df['bb_middle'] = df[close_col].rolling(window=period, min_periods=1).mean()
    bb_std = df[close_col].rolling(window=period, min_periods=1).std()
    df['bb_upper'] = df['bb_middle'] + (bb_std * std_dev)
    df['bb_lower'] = df['bb_middle'] - (bb_std * std_dev)
    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle'] * 100
    df['bb_position'] = (df[close_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower']) * 100
    return df

def calculate_atr(df, high_col, low_col, close_col, period=14):
    """ATR(Average True Range)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    high_low = df[high_col] - df[low_col]
    high_close = abs(df[high_col] - df[close_col].shift())
    low_close = abs(df[low_col] - df[close_col].shift())
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df['atr'] = true_range.rolling(window=period, min_periods=1).mean()
    return df

def calculate_volatility(df, close_col, periods=[20, 60]):
    """ë³€ë™ì„±ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    
    for period in periods:
        # ìˆ˜ìµë¥  ê³„ì‚°
        returns = df[close_col].pct_change()
        
        # ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
        df[f'volatility_{period}'] = returns.rolling(window=period, min_periods=1).std() * 100
        
        # ì—°ìœ¨í™”ëœ ë³€ë™ì„± (252ê±°ë˜ì¼ ê¸°ì¤€)
        df[f'volatility_annualized_{period}'] = returns.rolling(window=period, min_periods=1).std() * (252 ** 0.5) * 100
    
    return df

def calculate_parkinson_volatility(df, high_col, low_col, period=20):
    """Parkinson ë³€ë™ì„±ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ê³ ê°€-ì €ê°€ ê¸°ë°˜)"""
    df = df.copy()
    
    # ê³ ê°€/ì €ê°€ ë¹„ìœ¨ì˜ ë¡œê·¸
    log_hl_ratio = np.log(df[high_col] / df[low_col])
    
    # Parkinson ë³€ë™ì„± ê³„ì‚°
    df['parkinson_volatility'] = np.sqrt(
        (1 / (4 * np.log(2))) * 
        log_hl_ratio.rolling(window=period, min_periods=1).mean()
    ) * 100
    
    return df

def calculate_garman_klass_volatility(df, open_col, high_col, low_col, close_col, period=20):
    """Garman-Klass ë³€ë™ì„±ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (OHLC ê¸°ë°˜)"""
    df = df.copy()
    
    # Garman-Klass ë³€ë™ì„± ê³„ì‚°
    log_hl = np.log(df[high_col] / df[low_col])
    log_co = np.log(df[close_col] / df[open_col])
    
    volatility = np.sqrt(
        (0.5 * log_hl**2) - ((2*np.log(2) - 1) * log_co**2)
    )
    
    df['garman_klass_volatility'] = volatility.rolling(window=period, min_periods=1).mean() * 100
    
    return df

def calculate_true_range_volatility(df, high_col, low_col, close_col, period=20):
    """True Range ê¸°ë°˜ ë³€ë™ì„±ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    
    # True Range ê³„ì‚°
    high_low = df[high_col] - df[low_col]
    high_close = abs(df[high_col] - df[close_col].shift())
    low_close = abs(df[low_col] - df[close_col].shift())
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    
    # True Range ê¸°ë°˜ ë³€ë™ì„±
    df['true_range_volatility'] = (true_range / df[close_col]).rolling(window=period, min_periods=1).mean() * 100
    
    return df

def calculate_sharpe_ratio(df, close_col, periods=[20, 60, 120], risk_free_rate=0.02):
    """Sharpe ì§€ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    df = df.copy()
    
    # ìˆ˜ìµë¥  ê³„ì‚°
    returns = df[close_col].pct_change()
    
    for period in periods:
        # ê¸°ê°„ë³„ í‰ê·  ìˆ˜ìµë¥  (ì—°ìœ¨í™”)
        mean_return = returns.rolling(window=period, min_periods=1).mean() * 252
        
        # ê¸°ê°„ë³„ ìˆ˜ìµë¥  í‘œì¤€í¸ì°¨ (ì—°ìœ¨í™”)
        std_return = returns.rolling(window=period, min_periods=1).std() * (252 ** 0.5)
        
        # Sharpe ì§€ìˆ˜ ê³„ì‚°: (ìˆ˜ìµë¥  - ë¬´ìœ„í—˜ìˆ˜ìµë¥ ) / í‘œì¤€í¸ì°¨
        df[f'sharpe_ratio_{period}'] = (mean_return - risk_free_rate) / (std_return + 1e-8)
    
    return df

def calculate_sortino_ratio(df, close_col, periods=[20, 60, 120], risk_free_rate=0.02):
    """Sortino ì§€ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (í•˜ë°© ìœ„í—˜ë§Œ ê³ ë ¤)"""
    df = df.copy()
    
    # ìˆ˜ìµë¥  ê³„ì‚°
    returns = df[close_col].pct_change()
    
    for period in periods:
        # ê¸°ê°„ë³„ í‰ê·  ìˆ˜ìµë¥  (ì—°ìœ¨í™”)
        mean_return = returns.rolling(window=period, min_periods=1).mean() * 252
        
        # í•˜ë°© ìˆ˜ìµë¥ ë§Œ ì¶”ì¶œ (ìŒìˆ˜ ìˆ˜ìµë¥ )
        downside_returns = returns.where(returns < 0, 0)
        
        # í•˜ë°© í‘œì¤€í¸ì°¨ (ì—°ìœ¨í™”)
        downside_std = downside_returns.rolling(window=period, min_periods=1).std() * (252 ** 0.5)
        
        # Sortino ì§€ìˆ˜ ê³„ì‚°: (ìˆ˜ìµë¥  - ë¬´ìœ„í—˜ìˆ˜ìµë¥ ) / í•˜ë°©í‘œì¤€í¸ì°¨
        df[f'sortino_ratio_{period}'] = (mean_return - risk_free_rate) / (downside_std + 1e-8)
    
    return df

def calculate_calmar_ratio(df, close_col, periods=[20, 60, 120], risk_free_rate=0.02):
    """Calmar ì§€ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ìµœëŒ€ ë‚™í­ ëŒ€ë¹„ ìˆ˜ìµë¥ )"""
    df = df.copy()
    
    # ìˆ˜ìµë¥  ê³„ì‚°
    returns = df[close_col].pct_change()
    
    for period in periods:
        # ëˆ„ì  ìˆ˜ìµë¥  ê³„ì‚°
        cumulative_returns = (1 + returns).rolling(window=period, min_periods=1).apply(np.prod) - 1
        
        # ì—°ìœ¨í™”ëœ ìˆ˜ìµë¥ 
        annualized_return = ((1 + cumulative_returns) ** (252 / period)) - 1
        
        # ìµœëŒ€ ë‚™í­ ê³„ì‚°
        rolling_max = cumulative_returns.rolling(window=period, min_periods=1).max()
        drawdown = (cumulative_returns - rolling_max) / (rolling_max + 1e-8)
        max_drawdown = drawdown.rolling(window=period, min_periods=1).min()
        
        # Calmar ì§€ìˆ˜ ê³„ì‚°: (ìˆ˜ìµë¥  - ë¬´ìœ„í—˜ìˆ˜ìµë¥ ) / ìµœëŒ€ë‚™í­
        df[f'calmar_ratio_{period}'] = (annualized_return - risk_free_rate) / (abs(max_drawdown) + 1e-8)
    
    return df

# ---- ìœ í‹¸: í¬ë¡œìŠ¤ íƒì§€
def crossover(a, b):
    return (a > b) & (a.shift(1) <= b.shift(1))

def crossunder(a, b):
    return (a < b) & (a.shift(1) >= b.shift(1))

# ---- ì•ˆì „í•œ ìƒê´€ê´€ê³„ ê³„ì‚° (scipy ì—†ì´)
def safe_spearman_corr(x, y):
    """scipy ì—†ì´ Spearman ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ê²°ì¸¡ì¹˜ ì œê±°
        valid_mask = ~(x.isna() | y.isna())
        if valid_mask.sum() < 2:
            return 0.0
            
        x_clean = x[valid_mask]
        y_clean = y[valid_mask]
        
        # ìˆœìœ„ ê³„ì‚°
        x_rank = x_clean.rank()
        y_rank = y_clean.rank()
        
        # í‰ê·  ê³„ì‚°
        x_mean = x_rank.mean()
        y_mean = y_rank.mean()
        
        # ë¶„ì ê³„ì‚°: (x - x_mean) * (y - y_mean)ì˜ í•©
        numerator = ((x_rank - x_mean) * (y_rank - y_mean)).sum()
        
        # ë¶„ëª¨ ê³„ì‚°: sqrt(sum((x - x_mean)^2) * sum((y - y_mean)^2))
        x_var = ((x_rank - x_mean) ** 2).sum()
        y_var = ((y_rank - y_mean) ** 2).sum()
        denominator = (x_var * y_var) ** 0.5
        
        if denominator == 0:
            return 0.0
        
        return numerator / denominator
    except Exception as e:
        print(f"ìƒê´€ê´€ê³„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0

# ---- ì •ê·œí™”
def winsorize(s, p_low=0.01, p_high=0.99):
    lo, hi = s.quantile(p_low), s.quantile(p_high)
    return s.clip(lo, hi)

# ---- ê°œì„ ëœ ì •ê·œí™” í•¨ìˆ˜
def normalize(series, method="rank", winsor=None, clip=None, higher_is_better=True, mode=None):
    """ê°œì„ ëœ ì •ê·œí™” í•¨ìˆ˜ (ì§€ì‹œë¬¸ ê¸°ë°˜)"""
    s = series.copy()
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    s = s.fillna(0)
    
    if len(s) == 0:
        return pd.Series([50.0] * len(series), index=series.index)  # ì¤‘ê°„ê°’ ë°˜í™˜
    
    # ë‹¨ì¼ ê°’ì¸ ê²½ìš° ì¤‘ê°„ê°’ ë°˜í™˜
    if len(s) == 1:
        return pd.Series([50.0], index=s.index)
    
    # ê·¹ë‹¨ê°’ ì™„í™”
    if winsor:
        lo, hi = s.quantile(winsor[0]), s.quantile(winsor[1])
        s = s.clip(lo, hi)
    
    # ì •ê·œí™” ë°©ë²•
    if method == "minmax":
        rng = s.max() - s.min()
        out = (s - s.min()) / rng if rng != 0 else pd.Series(0.5, index=s.index)
    elif method == "zscore":
        std = s.std(ddof=0)
        out = (s - s.mean()) / (std if std else 1.0)
        # zëŠ” -3~+3 ì •ë„ê°€ ìì—°ìŠ¤ëŸ¬ì›€ â†’ 0~100ìœ¼ë¡œ ë§¤í•‘
        out = (out.clip(-3, 3) + 3) / 6
    elif method == "rank":
        out = s.rank(method="average", pct=True)
    else:
        out = s
    
    # ëª¨ë“œë³„ íŠ¹ë³„ ì²˜ë¦¬
    if mode == "revert":
        # ê·¹ë‹¨ íšŒê·€ ëª¨ë“œ: ì¤‘ê°„ê°’ì´ ì¢‹ìŒ (âˆ©ì í˜•íƒœ)
        out = 100 - abs(out - 50) * 2
        out = out.clip(0, 100)
    elif mode == "breakout":
        # ëŒíŒŒ ì¶”ì¢… ëª¨ë“œ: ê·¹ë‹¨ê°’ì´ ì¢‹ìŒ (ì„ í˜•)
        pass  # ê¸°ë³¸ ì²˜ë¦¬ ìœ ì§€
    
    if clip:
        out = out.clip(clip[0], clip[1])
    
    # ë°©í–¥ì„± ì¡°ì •
    if not higher_is_better:
        out = 100 - out
    
    # 0~100 ìŠ¤ì¼€ì¼
    out = (out - out.min()) / (out.max() - out.min() + 1e-12) * 100
    
    return out

# ---- ë¶ˆë¦¬ì–¸/ì´ë²¤íŠ¸ ì ìˆ˜
def eval_boolean_expr(df, expr):
    """ì»¬ëŸ¼ëª… ë§¤í•‘ì„ í¬í•¨í•œ ë¶ˆë¦¬ì–¸ í‘œí˜„ì‹ í‰ê°€"""
    # ì»¬ëŸ¼ëª… ë§¤í•‘
    column_mapping = {
        'close': 'ì¢…ê°€',
        'open': 'ì‹œê°€', 
        'high': 'ê³ ê°€',
        'low': 'ì €ê°€',
        'volume': 'ê±°ë˜ëŸ‰',
        'date': 'ê±°ë˜ì¼ì'
    }
    
    # í‘œí˜„ì‹ì—ì„œ ì»¬ëŸ¼ëª… ì¹˜í™˜
    modified_expr = expr
    for eng_name, kor_name in column_mapping.items():
        if kor_name in df.columns:
            modified_expr = modified_expr.replace(eng_name, kor_name)
    
    try:
        return pd.eval(modified_expr, local_dict=df.to_dict(orient="series"))
    except Exception as e:
        print(f"Expression evaluation error: {e}")
        print(f"Original expr: {expr}")
        print(f"Modified expr: {modified_expr}")
        print(f"Available columns: {list(df.columns)}")
        return pd.Series([False] * len(df), index=df.index)

def days_since_event(mask):
    # Trueì¸ ë‚ ì´ ì´ë²¤íŠ¸ ë°œìƒì¼. ì´í›„ ê²½ê³¼ì¼ ê³„ì‚°
    idx = mask.index
    last_day = -np.inf
    out = []
    for i, flag in enumerate(mask.values):
        if flag:
            last_day = i
        out.append(i - last_day if np.isfinite(last_day) else np.inf)
    return pd.Series(out, index=idx)

def apply_rules(df, rules):
    """ë£°ì„ ì ìš©í•˜ì—¬ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    rule_points = pd.Series(0.0, index=df.index)
    log_cols = {}
    
    for rule in rules:
        if rule["type"] == "boolean":
            m = eval_boolean_expr(df, rule["expr"])
            pts = np.where(m, rule["score"], 0.0)
        elif rule["type"] == "event_decay":
            ev = rule["event"]
            if ev.startswith("CROSSOVER("):
                a, b = ev[len("CROSSOVER("):-1].split(",")
                a, b = a.strip(), b.strip()
                m = crossover(df[a], df[b])
            elif ev.startswith("CROSSUNDER("):
                a, b = ev[len("CROSSUNDER("):-1].split(",")
                a, b = a.strip(), b.strip()
                m = crossunder(df[a], df[b])
            else:
                raise ValueError("Unknown event")
            t = days_since_event(m)
            decay = np.exp(-t / rule["tau"])
            pts = np.where(np.isfinite(t), rule["base"] * decay, 0.0)
        else:
            raise ValueError("Unknown rule type")
        rule_points += pts
        log_cols[rule["name"]] = pts
    
    # ë¹ˆ DataFrameì„ ë°˜í™˜í•  ë•Œ ì¸ë±ìŠ¤ ëª…ì‹œì  ì§€ì •
    if log_cols:
        return rule_points, pd.DataFrame(log_cols, index=df.index)
    else:
        return rule_points, pd.DataFrame(index=df.index)

# ---- ê°œì„ ëœ ìŠ¤ì½”ì–´ëŸ¬
def score_frame(df, config):
    """ê°œì„ ëœ ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ"""
    # ë‹¨ì¼ í–‰ì¸ ê²½ìš° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ ë‹¤ë¥´ê²Œ í•¨
    if len(df) == 1:
        # ë‹¨ì¼ í–‰ì˜ ê²½ìš° dropna() ëŒ€ì‹  ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì±„ì›€
        df = df.fillna(0)
    else:
        # ì—¬ëŸ¬ í–‰ì¸ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        df = df.ffill().dropna()
    
    if len(df) == 0:
        print("Warning: DataFrame is empty after processing")
        return pd.Series([0.0] * len(df), index=df.index), pd.DataFrame()
    
    # 1) ìˆ«ìí˜• í”¼ì²˜ ì ìˆ˜í™”
    num_cfg = config.get("numeric", {})
    num_log = {}
    total_num = pd.Series(0.0, index=df.index)
    
    for feat, spec in num_cfg.items():
        if feat not in df.columns:
            print(f"Feature {feat} not found in DataFrame")
            continue
            
        try:
            s = df[feat].astype(float)
            # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ê²½ìš° 0ìœ¼ë¡œ ì±„ì›€
            s = s.fillna(0)
            
            # ëª¨ë“  ê°’ì´ 0ì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
            if (s == 0).all():
                print(f"Feature {feat} has all zero values")
                continue
                
            vec = normalize(
                s,
                method=spec.get("norm", "rank"),
                winsor=spec.get("winsor", [0.02, 0.98]),
                clip=spec.get("clip"),
                higher_is_better=spec.get("higher_is_better", True),
                mode=spec.get("mode")  # ëª¨ë“œ ì§€ì› ì¶”ê°€
            )
            w = float(spec.get("weight", 0))
            total_num += vec * w
            num_log[f"[N] {feat}"] = vec * w
        except Exception as e:
            print(f"Error processing numeric feature {feat}: {e}")
            continue

    # 2) ë£° ì ìˆ˜í™”
    rule_points, rule_log = apply_rules(df, config.get("rules", []))

    # 3) í•©ì‚°
    total = total_num + rule_points

    # 4) í•„í„° ìƒí•œ ì ìš©
    cap_cfg = config.get("filters", {})
    if cap_cfg and cap_cfg.get("exprs"):
        pass_mask = np.ones(len(df), dtype=bool)
        for expr in cap_cfg["exprs"]:
            try:
                pass_mask &= eval_boolean_expr(df, expr).values
            except:
                pass_mask &= False
        
        cap_value = cap_cfg.get("cap_if_fail", 40.0)
        total = np.where(pass_mask, total, np.minimum(total, cap_value))
        total = pd.Series(total, index=df.index)

    # 5) ê¸°ì—¬ë„ ë¡œê·¸ ìƒì„±
    contrib = pd.concat([pd.DataFrame(num_log), rule_log], axis=1)
    contrib["TOTAL"] = total

    return total, contrib

def score_frame_single_row(df_row, config, all_results):
    """ë‹¨ì¼ í–‰ì— ëŒ€í•´ ì „ì²´ ì¢…ëª© ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ì—¬ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    if len(df_row) == 0:
        return pd.Series([0.0] * len(df_row), index=df_row.index), pd.DataFrame()
    
    # 1) ìˆ«ìí˜• í”¼ì²˜ ì ìˆ˜í™” (ì „ì²´ ì¢…ëª© ë°ì´í„° ì°¸ì¡°)
    num_cfg = config.get("numeric", {})
    num_log = {}
    total_num = pd.Series(0.0, index=df_row.index)
    
    for feat, spec in num_cfg.items():
        if feat not in df_row.columns:
            print(f"Feature {feat} not found in DataFrame")
            continue
            
        try:
            # í˜„ì¬ ì¢…ëª©ì˜ ê°’
            current_value = df_row[feat].iloc[0]
            
            # ì „ì²´ ì¢…ëª©ì—ì„œ í•´ë‹¹ í”¼ì²˜ì˜ ê°’ë“¤ì„ ìˆ˜ì§‘
            all_values = []
            for result in all_results:
                if feat in result:
                    all_values.append(result[feat])
            
            # ì „ì²´ ì¢…ëª© ë°ì´í„°ë¡œ ì •ê·œí™”
            if len(all_values) > 1:
                all_series = pd.Series(all_values)
                normalized_value = normalize_single_value(
                    current_value, 
                    all_series,
                    method=spec.get("norm", "rank"),
                    winsor=spec.get("winsor", [0.02, 0.98]),
                    clip=spec.get("clip"),
                    higher_is_better=spec.get("higher_is_better", True)
                )
            else:
                normalized_value = 50.0  # ê¸°ë³¸ê°’
            
            w = float(spec.get("weight", 0))
            total_num += normalized_value * w
            num_log[f"[N] {feat}"] = normalized_value * w
            print(f"Normalized {feat}: {normalized_value:.2f}, weight: {w}, contribution: {normalized_value * w:.2f}")
        except Exception as e:
            print(f"Error processing numeric feature {feat}: {e}")
            continue

    # 2) ë£° ì ìˆ˜í™”
    rule_points, rule_log = apply_rules(df_row, config.get("rules", []))

    # 3) í•©ì‚°
    total = total_num + rule_points
    print(f"Total score before filter: {total.values}")

    # 4) í•„í„° ìƒí•œ ì ìš© (ë””ë²„ê¹… ì¶”ê°€)
    cap_cfg = config.get("filters", {})
    if cap_cfg and cap_cfg.get("exprs"):
        pass_mask = np.ones(len(df_row), dtype=bool)
        print(f"Filter expressions: {cap_cfg['exprs']}")
        
        for expr in cap_cfg["exprs"]:
            try:
                result = eval_boolean_expr(df_row, expr)
                print(f"Filter '{expr}' result: {result.values}")
                pass_mask &= result.values
            except Exception as e:
                print(f"Filter '{expr}' error: {e}")
                pass_mask &= False
        
        print(f"Final pass_mask: {pass_mask}")
        cap_value = cap_cfg.get("cap_if_fail", 40.0)
        total = np.where(pass_mask, total, np.minimum(total, cap_value))
        total = pd.Series(total, index=df_row.index)
        print(f"Total score after filter: {total.values}")

    # 5) ê¸°ì—¬ë„ ë¡œê·¸ ìƒì„± (ì¸ë±ìŠ¤ ëª…ì‹œì  ì§€ì •)
    if num_log:
        num_df = pd.DataFrame([num_log], index=df_row.index)
    else:
        num_df = pd.DataFrame(index=df_row.index)
    
    if not rule_log.empty:
        contrib = pd.concat([num_df, rule_log], axis=1)
    else:
        contrib = num_df
    
    contrib["TOTAL"] = total

    return total, contrib

def normalize_single_value(value, all_values, method="rank", winsor=None, clip=None, higher_is_better=True):
    """ë‹¨ì¼ ê°’ì„ ì „ì²´ ê°’ë“¤ê³¼ ë¹„êµí•˜ì—¬ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜"""
    if len(all_values) == 0:
        return 50.0
    
    # ê·¹ë‹¨ê°’ ì™„í™”
    if winsor:
        lo, hi = all_values.quantile(winsor[0]), all_values.quantile(winsor[1])
        all_values = all_values.clip(lo, hi)
        value = np.clip(value, lo, hi)
    
    # ì •ê·œí™” ë°©ë²•
    if method == "minmax":
        rng = all_values.max() - all_values.min()
        if rng != 0:
            out = (value - all_values.min()) / rng
        else:
            out = 0.5
    elif method == "zscore":
        std = all_values.std(ddof=0)
        if std != 0:
            out = (value - all_values.mean()) / std
            # z-scoreë¥¼ 0~100ìœ¼ë¡œ ë§¤í•‘ (-3~+3 ë²”ìœ„)
            out = (np.clip(out, -3, 3) + 3) / 6
        else:
            out = 0.5
    elif method == "rank":
        # í˜„ì¬ ê°’ì´ ì „ì²´ì—ì„œ ëª‡ ë²ˆì§¸ì¸ì§€ ê³„ì‚°
        rank = (all_values < value).sum() + 1
        out = rank / len(all_values)
    else:
        out = 0.5
    
    # í´ë¦¬í•‘
    if clip:
        out = np.clip(out, clip[0], clip[1])
    
    # 0~100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    out = out * 100
    
    # ë°©í–¥ì„± ì¡°ì •
    if not higher_is_better:
        out = 100 - out
    
    return out



# ---- ê³ ê¸‰ ìŠ¤ì½”ì–´ë§ ì„¤ì • (ì§€ì‹œë¬¸ ê¸°ë°˜ ê°œì„ )
ADVANCED_SCORE_CONFIG = {
    "numeric": {
        # ìƒìŠ¹ë¥  ì§€í‘œ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        "return_20d": {"weight": 0.18, "norm": "rank", "winsor": [0.02, 0.98], "higher_is_better": True},
        "return_60d": {"weight": 0.12, "norm": "rank", "winsor": [0.02, 0.98], "higher_is_better": True},
        
        # ìƒëŒ€ ëª¨ë©˜í…€ ì§€í‘œ (í•µì‹¬ ê°€ì¤‘ì¹˜)
        "rel_mom_20": {"weight": 0.20, "norm": "rank", "higher_is_better": True},
        "rel_mom_60": {"weight": 0.15, "norm": "rank", "higher_is_better": True},
        "rel_mom_120": {"weight": 0.15, "norm": "rank", "higher_is_better": True},
        
        # ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥  ì§€í‘œ (í€„ë¦¬í‹° ë ˆì´ì–´)
        "sharpe_ratio_60": {"weight": 0.10, "norm": "rank", "higher_is_better": True},
        "sortino_ratio_60": {"weight": 0.08, "norm": "rank", "higher_is_better": True},
        "calmar_ratio_120": {"weight": 0.08, "norm": "rank", "higher_is_better": True},
        
        # ë³€ë™ì„± ì§€í‘œ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        "volatility_20": {"weight": 0.07, "norm": "rank", "higher_is_better": False},
        "volatility_60": {"weight": 0.05, "norm": "rank", "higher_is_better": False},
        
        # ë³¼ë¦°ì € ë°´ë“œ (ê·¹ë‹¨ íšŒê·€ ëª¨ë“œ)
        "bb_position": {"weight": 0.05, "norm": "minmax", "mode": "revert", "higher_is_better": False},
        "bb_width": {"weight": 0.03, "norm": "rank", "higher_is_better": False},
        
        # ê±°ë˜ëŸ‰ ì§€í‘œ
        "volume_ratio": {"weight": 0.07, "norm": "rank", "higher_is_better": True},
        
        # 52ì£¼ ê³ ì /ì €ì  (ëŒíŒŒ ì¶”ì¢… ëª¨ë“œ)
        "high_52w_ratio": {"weight": 0.15, "norm": "zscore", "clip": [-2.5, 2.5], "higher_is_better": True},
        "low_52w_ratio": {"weight": 0.05, "norm": "rank", "higher_is_better": False},
        
        # ê¸°ìˆ ì  ì§€í‘œ
        "rsi": {"weight": 0.05, "norm": "minmax", "higher_is_better": False},  # 50 ê·¼ì²˜ê°€ ì¢‹ìŒ
    },
    
    "rules": [
        # ì¶”ì„¸ í•„í„° (í•µì‹¬)
        {
            "name": "TrendFilter",
            "type": "boolean",
            "expr": "sma20 > sma60 * 1.002 and close > sma20",
            "score": 8.0
        },
        
        # ì´ë™í‰ê·  ì •ë ¬
        {
            "name": "MAAlignment",
            "type": "boolean",
            "expr": "sma5 > sma20 and sma20 > sma60",
            "score": 6.0
        },
        
        # RSI ê±´ê°•í•œ êµ¬ê°„
        {
            "name": "RSI_Healthy",
            "type": "boolean",
            "expr": "rsi >= 50 and rsi <= 70",
            "score": 4.0
        },
        
        # RSI ê³¼ë§¤ë„ (ë°˜ë“± ê¸°ëŒ€)
        {
            "name": "RSI_Oversold",
            "type": "boolean",
            "expr": "rsi < 30",
            "score": 5.0
        },
        
        # MACD ìƒí–¥ ì „í™˜
        {
            "name": "MACD_TurnUp",
            "type": "boolean",
            "expr": "macd_histogram > 0 and macd_histogram.shift(1) <= 0",
            "score": 6.0
        },
        
        # ê±°ë˜ëŸ‰ ê¸‰ì¦
        {
            "name": "Volume_Surge",
            "type": "boolean",
            "expr": "volume_ratio > 1.5",
            "score": 4.0
        },
        
        # ê³¨ë“ í¬ë¡œìŠ¤ ì´ë²¤íŠ¸ (ê°ì‡  ì ìš©)
        {
            "name": "Golden_20_60",
            "type": "event_decay",
            "event": "CROSSOVER(sma20, sma60)",
            "base": 12.0,
            "tau": 5.0
        },
        
        # ë°ë“œí¬ë¡œìŠ¤ ì´ë²¤íŠ¸ (ê°ì‡  ì ìš©)
        {
            "name": "Dead_20_60",
            "type": "event_decay",
            "event": "CROSSUNDER(sma20, sma60)",
            "base": -14.0,
            "tau": 5.0
        },
        
        # ë³¼ë¦°ì € ë°´ë“œ í•˜ë‹¨ ë°˜ë“±
        {
            "name": "BB_Bounce",
            "type": "boolean",
            "expr": "bb_position < 0.2 and close > close.shift(1)",
            "score": 5.0
        },
        
        # 52ì£¼ ê³ ì  ê·¼ì ‘
        {
            "name": "52W_High_Near",
            "type": "boolean",
            "expr": "high_52w_ratio > 95 and high_52w_ratio < 99",
            "score": 3.0
        }
    ],
    
    "filters": {
        "cap_if_fail": 40.0,
        "exprs": [
            "close > sma20",
            "sma20 > sma60"
        ]
    },
    
    "thresholds": {
        "buy": 70,
        "hold": 55,
        "sell": 50
    }
}

# ë‹¨ìˆœí™”ëœ ìŠ¤ì½”ì–´ë§ ì„¤ì • (ë””ë²„ê¹…ìš©)
SIMPLE_SCORE_CONFIG = {
    "numeric": {
        # ê¸°ë³¸ ì§€í‘œë“¤ë§Œ ì‚¬ìš©
        "return_20d": {"weight": 0.3, "norm": "rank", "higher_is_better": True},
        "rel_mom_20": {"weight": 0.3, "norm": "rank", "higher_is_better": True},
        "rsi": {"weight": 0.2, "norm": "minmax", "higher_is_better": False},
        "volume_ratio": {"weight": 0.2, "norm": "rank", "higher_is_better": True},
    },
    "rules": [
        {
            "name": "TrendFilter",
            "type": "boolean",
            "expr": "sma20 > sma60",
            "score": 10.0
        }
    ],
    "filters": {
        "cap_if_fail": 50.0,
        "exprs": []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
    }
}

# ---- ìŠ¤ì½”ì–´ë§ ê²°ê³¼ ë¶„ì„ í—¬í¼
def analyze_score_contribution(contrib_df, top_n=5):
    """ìŠ¤ì½”ì–´ ê¸°ì—¬ë„ ë¶„ì„"""
    if contrib_df.empty:
        return pd.DataFrame()
    
    # í‰ê·  ê¸°ì—¬ë„ ê³„ì‚°
    avg_contrib = contrib_df.mean().sort_values(ascending=False)
    
    # ìƒìœ„ ê¸°ì—¬ë„ë§Œ ì„ íƒ
    top_contrib = avg_contrib.head(top_n)
    
    return pd.DataFrame({
        'Feature': top_contrib.index,
        'Avg_Contribution': top_contrib.values,
        'Percentage': (top_contrib.values / top_contrib.sum() * 100).round(2)
    })

# ì£¼ì‹ ì¢…ëª© ì½”ë“œì™€ ì´ë¦„ ë§¤í•‘ (KODEX 200 ì œì™¸, ì‹¤ì œ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ì—…ë°ì´íŠ¸)
CODE_TO_NAME = {
    "000270": "Kia",
    "000660": "SK Hynix",
    "000810": "ì‚¼ì„±í™”ì¬",
    "005380": "Hyundai Motor",
    "005490": "POSCO",
    "005930": "Samsung Electronics",
    "005935": "Samsung Electronics (ìš°ì„ ì£¼)",
    "009540": "í˜„ëŒ€ì¤‘ê³µì—…",
    "011200": "HMM",
    "012330": "í˜„ëŒ€ëª¨ë¹„ìŠ¤",
    "012450": "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤",
    "015760": "í•œêµ­ì „ë ¥",
    "028260": "ì‚¼ì„±ë¬¼ì‚°",
    "032830": "ì‚¼ì„±ìƒëª…",
    "034020": "Doosan Enerbility",
    "035420": "NAVER",
    "035720": "ì¹´ì¹´ì˜¤",
    "042660": "ëŒ€ìš°ê±´ì„¤",
    "051910": "LG Chem",
    "055550": "ì‹ í•œì§€ì£¼",
    "064350": "í˜„ëŒ€ë¡œí…œ",
    "068270": "Celltrion",
    "086790": "í•˜ë‚˜ê¸ˆìœµì§€ì£¼",
    "105560": "KB Financial",
    "138040": "ë©”ë¦¬ì¸ ê¸ˆìœµì§€ì£¼",
    "207940": "Samsung Biologics",
    "316140": "ìš°ë¦¬ê¸ˆìœµì§€ì£¼",
    "329180": "HD Hyundai Construction Equipment",
    "373220": "LG Energy Solution",
    "402340": "SKìŠ¤í€˜ì–´"
}

DATA_FOLDER = "/home/hanmil/backtest_app2"
st.set_page_config(page_title="Stock Analysis Dashboard", layout="wide")
st.title("Stock Analysis Dashboard")

# KODEX 200 ë°ì´í„°ì—ì„œ ê±°ë˜ì¼ ì¶”ì¶œ
def get_trading_dates():
    try:
        df_kodex = pd.read_csv(os.path.join(DATA_FOLDER, "069500_daily_price.csv"))
        date_col = find_column(df_kodex, ['ê±°ë˜ì¼ì', 'date', 'Date', 'ë‚ ì§œ'])
        if date_col:
            # YYYYMMDD í˜•ì‹ì„ ì˜¬ë°”ë¥´ê²Œ íŒŒì‹±
            df_kodex[date_col] = pd.to_datetime(df_kodex[date_col], format='%Y%m%d')
            trading_dates = df_kodex[date_col].dt.date.unique()
            trading_dates = sorted(trading_dates)
            return trading_dates
        else:
            st.error("ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
    except Exception as e:
        st.error(f"KODEX 200 ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

# ê±°ë˜ì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
trading_dates = get_trading_dates()

# ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
st.write(f"**ì „ì²´ ê±°ë˜ì¼ ìˆ˜**: {len(trading_dates) if trading_dates else 0}")

if trading_dates:
    # ê±°ë˜ì¼ ë²”ìœ„ ê³„ì‚°
    min_date = min(trading_dates)
    max_date = max(trading_dates)
    
    # 2023ë…„ 7ì›” 3ì¼ë¶€í„° 2025ë…„ 6ì›” 30ì¼ê¹Œì§€ì˜ ê±°ë˜ì¼ í•„í„°ë§
    start_limit = dt.date(2023, 7, 3)
    end_limit = dt.date(2025, 6, 30)
    filtered_trading_dates = [d for d in trading_dates if start_limit <= d <= end_limit]
    
    st.write(f"**í•„í„°ë§ëœ ê±°ë˜ì¼ ìˆ˜**: {len(filtered_trading_dates)}")
    st.write(f"**ì „ì²´ ë°ì´í„° ë²”ìœ„**: {min_date} ~ {max_date}")
    st.write(f"**í•„í„°ë§ ë²”ìœ„**: {start_limit} ~ {end_limit}")
    
    if filtered_trading_dates:
        # ì—°ë„ë³„, ì›”ë³„, ì¼ë³„ë¡œ ê±°ë˜ì¼ ê·¸ë£¹í™”
        years = sorted(list(set(d.year for d in filtered_trading_dates)))
        years_str = [str(year) for year in years]
        
        # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ì„ íƒ
        st.subheader("ê¸°ê°„ ì„ íƒ")
        st.write("ê±°ë˜ì¼ë§Œ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤ (2023ë…„ 7ì›” 3ì¼ ~ 2025ë…„ 6ì›” 30ì¼)")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ì‹œì‘ì¼**")
            start_year = st.selectbox("ì—°ë„", years_str, index=0, key="start_year")
            start_year_dates = [d for d in filtered_trading_dates if d.year == int(start_year)]
            start_months = sorted(list(set(d.month for d in start_year_dates)))
            start_months_str = [f"{month:02d}ì›”" for month in start_months]
            start_month = st.selectbox("ì›”", start_months_str, key="start_month")
            start_month_num = int(start_month.replace("ì›”", ""))
            start_month_dates = [d for d in start_year_dates if d.month == start_month_num]
            start_days = sorted(list(set(d.day for d in start_month_dates)))
            start_days_str = [f"{day:02d}ì¼" for day in start_days]
            start_day = st.selectbox("ì¼", start_days_str, key="start_day")
            start_day_num = int(start_day.replace("ì¼", ""))
            start_date = dt.date(int(start_year), start_month_num, start_day_num)
            
        with col2:
            st.write("**ì¢…ë£Œì¼**")
            end_year = st.selectbox("ì—°ë„", years_str, index=len(years_str)-1, key="end_year")
            end_year_dates = [d for d in filtered_trading_dates if d.year == int(end_year)]
            end_months = sorted(list(set(d.month for d in end_year_dates)))
            end_months_str = [f"{month:02d}ì›”" for month in end_months]
            end_month = st.selectbox("ì›”", end_months_str, index=len(end_months_str)-1, key="end_month")
            end_month_num = int(end_month.replace("ì›”", ""))
            end_month_dates = [d for d in end_year_dates if d.month == end_month_num]
            end_days = sorted(list(set(d.day for d in end_month_dates)))
            end_days_str = [f"{day:02d}ì¼" for day in end_days]
            end_day = st.selectbox("ì¼", end_days_str, index=len(end_days_str)-1, key="end_day")
            end_day_num = int(end_day.replace("ì¼", ""))
            end_date = dt.date(int(end_year), end_month_num, end_day_num)
        
        # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
        if start_date > end_date:
            st.error("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            st.success(f"ì„ íƒëœ ê¸°ê°„: {start_date} ~ {end_date}")

            # ê±°ë˜ì¼ ì •ë³´ í‘œì‹œ
            with st.expander("ê±°ë˜ì¼ ì •ë³´"):
                st.write(f"**ì „ì²´ ë°ì´í„° ë²”ìœ„**: {min_date} ~ {max_date}")
                st.write(f"**ì„ íƒ ê°€ëŠ¥ ë²”ìœ„**: {start_limit} ~ {end_limit}")
                st.write(f"**ì„ íƒ ê°€ëŠ¥í•œ ê±°ë˜ì¼ ìˆ˜**: {len(filtered_trading_dates)}ì¼")
                st.write(f"**ì„ íƒëœ ê¸°ê°„**: {start_date} ~ {end_date}")
                
                # ì„ íƒëœ ê¸°ê°„ì˜ ê±°ë˜ì¼ ìˆ˜ ê³„ì‚°
                selected_trading_dates = [d for d in filtered_trading_dates if start_date <= d <= end_date]
                st.write(f"**ì„ íƒëœ ê¸°ê°„ ê±°ë˜ì¼ ìˆ˜**: {len(selected_trading_dates)}ì¼")
    else:
        st.error("í•„í„°ë§ëœ ê±°ë˜ì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ë²”ìœ„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    st.error("ê±°ë˜ì¼ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ==============================
# ì£¼ì‹ ì¢…ëª© ì„ íƒ (Opt-out ë°©ì‹)
# ==============================
st.subheader("ì£¼ì‹ ì¢…ëª© ì„ íƒ")

file_paths = sorted(glob(os.path.join(DATA_FOLDER, "*_daily_price.csv")))
stock_codes = [os.path.basename(p).split("_")[0] for p in file_paths if os.path.basename(p).split("_")[0] != "069500"]  # KODEX 200 ì œì™¸
stock_names = [f"{CODE_TO_NAME.get(code, code)} ({code})" for code in stock_codes]

# ê¸°ë³¸ê°’ìœ¼ë¡œ ëª¨ë“  ì¢…ëª© ì„ íƒ
default_selected = stock_names.copy()

# ì œì™¸í•  ì¢…ëª© ì„ íƒ (Opt-out)
excluded_stocks = st.multiselect(
    "ì œì™¸í•  ì¢…ëª© ì„ íƒ (ê¸°ë³¸ê°’: ëª¨ë“  ì¢…ëª© ì„ íƒ)", 
    options=stock_names,
    help="ì„ íƒí•œ ì¢…ëª©ë“¤ì€ ë¶„ì„ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë“  ì¢…ëª©ì´ ë¶„ì„ ëŒ€ìƒì…ë‹ˆë‹¤."
)

# ìµœì¢… ì„ íƒëœ ì¢…ëª© ê³„ì‚°
selected_stocks = [name for name in default_selected if name not in excluded_stocks]
selected_codes = [name.split("(")[-1][:-1] for name in selected_stocks]

st.write(f"**ë¶„ì„ ëŒ€ìƒ ì¢…ëª© ìˆ˜**: {len(selected_codes)}ê°œ")
if selected_codes:
    st.write(f"**ë¶„ì„ ëŒ€ìƒ**: {', '.join([CODE_TO_NAME.get(code, code) for code in selected_codes[:5]])}{'...' if len(selected_codes) > 5 else ''}")

# ==============================
# ì‚¬ìš© ê°€ëŠ¥í•œ Feature ëª©ë¡
# ==============================
st.subheader("ì‚¬ìš© ê°€ëŠ¥í•œ Feature ëª©ë¡")

# Feature ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‘œì‹œ
feature_categories = {
    "ê¸°ë³¸ ê°€ê²© ë°ì´í„°": ["close", "open", "high", "low", "volume"],
    "ì´ë™í‰ê· ì„ ": ["sma5", "sma10", "sma20", "sma60", "sma120"],
    "ì§€ìˆ˜ì´ë™í‰ê· ì„ ": ["ema12", "ema26"],
    "ê¸°ìˆ ì  ì§€í‘œ": ["rsi", "macd", "macd_signal", "macd_histogram"],
    "ë³¼ë¦°ì € ë°´ë“œ": ["bb_upper", "bb_middle", "bb_lower", "bb_width", "bb_position"],
    "ê±°ë˜ëŸ‰ ì§€í‘œ": ["volume_sma5", "volume_sma20", "volume_ratio"],
    "ë³€ë™ì„± ì§€í‘œ": ["atr", "volatility_20", "volatility_60", "volatility_annualized_20", "volatility_annualized_60", "parkinson_volatility", "garman_klass_volatility", "true_range_volatility"],
    "ìƒìŠ¹ë¥  ì§€í‘œ": ["return_2d", "return_20d", "return_60d"],
    "ìƒëŒ€ ëª¨ë©˜í…€ ì§€í‘œ": ["rel_mom_20", "rel_mom_60", "rel_mom_120"],
    "52ì£¼ ê³ ì /ì €ì  ì§€í‘œ": ["high_52w_ratio", "low_52w_ratio"],
    "ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥  ì§€í‘œ": ["sharpe_ratio_20", "sharpe_ratio_60", "sharpe_ratio_120", "sortino_ratio_20", "sortino_ratio_60", "sortino_ratio_120", "calmar_ratio_20", "calmar_ratio_60", "calmar_ratio_120"]
}

for category, features in feature_categories.items():
    with st.expander(f"{category} ({len(features)}ê°œ)"):
        # 3ì—´ë¡œ í‘œì‹œ
        cols = st.columns(3)
        for i, feature in enumerate(features):
            col_idx = i % 3
            with cols[col_idx]:
                st.write(f"â€¢ **{feature}**")
        
        # ì„¤ëª… ì¶”ê°€
        if category == "ê¸°ë³¸ ê°€ê²© ë°ì´í„°":
            st.write("**ì„¤ëª…**: ì£¼ì‹ì˜ ê¸°ë³¸ ê°€ê²© ì •ë³´ (ì¢…ê°€, ì‹œê°€, ê³ ê°€, ì €ê°€, ê±°ë˜ëŸ‰)")
        elif category == "ì´ë™í‰ê· ì„ ":
            st.write("**ì„¤ëª…**: ë‹¨ìˆœì´ë™í‰ê· ì„  (Simple Moving Average)")
        elif category == "ì§€ìˆ˜ì´ë™í‰ê· ì„ ":
            st.write("**ì„¤ëª…**: ì§€ìˆ˜ì´ë™í‰ê· ì„  (Exponential Moving Average)")
        elif category == "ê¸°ìˆ ì  ì§€í‘œ":
            st.write("**ì„¤ëª…**: RSI (ìƒëŒ€ê°•ë„ì§€ìˆ˜), MACD (ì´ë™í‰ê· ìˆ˜ë ´í™•ì‚°ì§€ìˆ˜)")
        elif category == "ë³¼ë¦°ì € ë°´ë“œ":
            st.write("**ì„¤ëª…**: ë³¼ë¦°ì € ë°´ë“œ (Bollinger Bands) - ë³€ë™ì„± ê¸°ë°˜ ì§€í‘œ")
        elif category == "ê±°ë˜ëŸ‰ ì§€í‘œ":
            st.write("**ì„¤ëª…**: ê±°ë˜ëŸ‰ ê¸°ë°˜ ì§€í‘œ (ê±°ë˜ëŸ‰ ì´ë™í‰ê· , ê±°ë˜ëŸ‰ ë¹„ìœ¨)")
        elif category == "ë³€ë™ì„± ì§€í‘œ":
            st.write("**ì„¤ëª…**: ë‹¤ì–‘í•œ ë³€ë™ì„± ê³„ì‚° ë°©ë²• (ATR, Parkinson, Garman-Klass ë“±)")
        elif category == "ìƒìŠ¹ë¥  ì§€í‘œ":
            st.write("**ì„¤ëª…**: ê³¼ê±° ëŒ€ë¹„ ê°€ê²© ìƒìŠ¹ë¥  (2ì¼, 20ì¼, 60ì¼)")
        elif category == "ìƒëŒ€ ëª¨ë©˜í…€ ì§€í‘œ":
            st.write("**ì„¤ëª…**: KODEX 200 ëŒ€ë¹„ ìƒëŒ€ì  ëª¨ë©˜í…€")
        elif category == "52ì£¼ ê³ ì /ì €ì  ì§€í‘œ":
            st.write("**ì„¤ëª…**: 52ì£¼ ê³ ì /ì €ì  ëŒ€ë¹„ í˜„ì¬ê°€ ë¹„ìœ¨")
        elif category == "ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥  ì§€í‘œ":
            st.write("**ì„¤ëª…**: ìœ„í—˜ ëŒ€ë¹„ ì´ˆê³¼ìˆ˜ìµë¥ ì„ ì¸¡ì •í•˜ëŠ” ì§€í‘œ (Sharpe, Sortino, Calmar)")

# Feature ì‚¬ìš© ì˜ˆì‹œ
with st.expander("Feature ì‚¬ìš© ì˜ˆì‹œ"):
    st.write("**ì¡°ê±´ ì„¤ì • ì˜ˆì‹œ**:")
    st.write("â€¢ `rsi < 30` : RSIê°€ 30 ë¯¸ë§Œì¼ ë•Œ (ê³¼ë§¤ë„)")
    st.write("â€¢ `rsi > 70` : RSIê°€ 70 ì´ˆê³¼ì¼ ë•Œ (ê³¼ë§¤ìˆ˜)")
    st.write("â€¢ `close > sma20` : ì¢…ê°€ê°€ 20ì¼ ì´ë™í‰ê· ì„  ìœ„ì— ìˆì„ ë•Œ")
    st.write("â€¢ `volume_ratio > 2` : ê±°ë˜ëŸ‰ì´ 20ì¼ í‰ê· ì˜ 2ë°° ì´ìƒì¼ ë•Œ")
    st.write("â€¢ `volatility_20 > 3` : 20ì¼ ë³€ë™ì„±ì´ 3% ì´ìƒì¼ ë•Œ")
    st.write("â€¢ `high_52w_ratio > 95` : 52ì£¼ ê³ ì ì˜ 95% ì´ìƒì¼ ë•Œ")
    st.write("â€¢ `rel_mom_20 > 5` : KODEX 200 ëŒ€ë¹„ 20ì¼ ìƒëŒ€ ëª¨ë©˜í…€ì´ 5% ì´ìƒì¼ ë•Œ")

# ==============================
# ì ìˆ˜ ê³„ì‚° ì„¤ì • (ì‚¬ìš©ì ì •ì˜)
# ==============================
st.subheader("ì ìˆ˜ ê³„ì‚° ì„¤ì •")

# ì‚¬ìš© ê°€ëŠ¥í•œ ì§€í‘œ ëª©ë¡
available_indicators = {
    "ìƒìŠ¹ë¥  ì§€í‘œ": {
        "return_2d": "2ì¼ ìƒìŠ¹ë¥ ",
        "return_20d": "20ì¼ ìƒìŠ¹ë¥ ", 
        "return_60d": "60ì¼ ìƒìŠ¹ë¥ "
    },
    "ìƒëŒ€ ëª¨ë©˜í…€ ì§€í‘œ": {
        "rel_mom_20": "20ì¼ ìƒëŒ€ ëª¨ë©˜í…€",
        "rel_mom_60": "60ì¼ ìƒëŒ€ ëª¨ë©˜í…€",
        "rel_mom_120": "120ì¼ ìƒëŒ€ ëª¨ë©˜í…€"
    },
    "ê¸°ìˆ ì  ì§€í‘œ": {
        "rsi": "RSI",
        "macd": "MACD",
        "macd_histogram": "MACD íˆìŠ¤í† ê·¸ë¨"
    },
    "ì´ë™í‰ê· ì„ ": {
        "sma5": "5ì¼ ì´ë™í‰ê· ",
        "sma20": "20ì¼ ì´ë™í‰ê· ",
        "sma60": "60ì¼ ì´ë™í‰ê· "
    },
    "ë³¼ë¦°ì € ë°´ë“œ": {
        "bb_position": "ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜",
        "bb_width": "ë³¼ë¦°ì € ë°´ë“œ í­"
    },
    "ê±°ë˜ëŸ‰ ì§€í‘œ": {
        "volume_ratio": "ê±°ë˜ëŸ‰ ë¹„ìœ¨",
        "volume_sma5": "ê±°ë˜ëŸ‰ 5ì¼ í‰ê· ",
        "volume_sma20": "ê±°ë˜ëŸ‰ 20ì¼ í‰ê· "
    },
    "ë³€ë™ì„± ì§€í‘œ": {
        "volatility_20": "20ì¼ ë³€ë™ì„±",
        "volatility_60": "60ì¼ ë³€ë™ì„±",
        "atr": "ATR"
    },
    "52ì£¼ ê³ ì /ì €ì ": {
        "high_52w_ratio": "52ì£¼ ê³ ì  ë¹„ìœ¨",
        "low_52w_ratio": "52ì£¼ ì €ì  ë¹„ìœ¨"
    },
    "ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥ ": {
        "sharpe_ratio_20": "20ì¼ ìƒ¤í”„ ë¹„ìœ¨",
        "sharpe_ratio_60": "60ì¼ ìƒ¤í”„ ë¹„ìœ¨",
        "sortino_ratio_60": "60ì¼ ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨",
        "calmar_ratio_120": "120ì¼ ì¹¼ë§ˆ ë¹„ìœ¨"
    }
}

# ê¸°ë³¸ ì„¤ì •
default_indicators = {
    "return_20d": {"weight": 0.25, "norm": "rank", "higher_is_better": True},
    "rel_mom_20": {"weight": 0.25, "norm": "rank", "higher_is_better": True},
    "rsi": {"weight": 0.20, "norm": "minmax", "higher_is_better": False},
    "volume_ratio": {"weight": 0.15, "norm": "rank", "higher_is_better": True},
    "sharpe_ratio_60": {"weight": 0.15, "norm": "rank", "higher_is_better": True}
}

# ì‚¬ìš©ì ì •ì˜ ì„¤ì •
st.write("**ì§€í‘œ ì„ íƒ ë° ê°€ì¤‘ì¹˜ ì„¤ì •**")
st.write("ê°€ì¤‘ì¹˜ ì´í•©ì´ 1.0ì´ ë˜ë„ë¡ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# íƒ­ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ êµ¬ë¶„
tab_names = list(available_indicators.keys())
tabs = st.tabs(tab_names)

# session_stateì—ì„œ selected_indicators ì´ˆê¸°í™”
if 'selected_indicators' not in st.session_state:
    st.session_state.selected_indicators = {}

selected_indicators = st.session_state.selected_indicators
total_weight = 0.0

for i, (category, indicators) in enumerate(available_indicators.items()):
    with tabs[i]:
        st.write(f"**{category}**")
        
        for indicator_code, indicator_name in indicators.items():
            col1, col2, col3, col4 = st.columns([3, 2, 2, 1])
            
            with col1:
                # ì§€í‘œ ì„ íƒ ì²´í¬ë°•ìŠ¤
                is_selected = st.checkbox(
                    indicator_name, 
                    value=indicator_code in default_indicators,
                    key=f"select_{indicator_code}"
                )
            
            if is_selected:
                with col2:
                    # ê°€ì¤‘ì¹˜ ì…ë ¥
                    weight = st.number_input(
                        "ê°€ì¤‘ì¹˜",
                        min_value=0.0,
                        max_value=1.0,
                        value=default_indicators.get(indicator_code, {}).get("weight", 0.1),
                        step=0.05,
                        format="%.2f",
                        key=f"weight_{indicator_code}"
                    )
                
                with col3:
                    # ì •ê·œí™” ë°©ë²• ì„ íƒ
                    norm_method = st.selectbox(
                        "ì •ê·œí™”",
                        options=["rank", "minmax", "zscore"],
                        index=0 if default_indicators.get(indicator_code, {}).get("norm", "rank") == "rank" else 
                              1 if default_indicators.get(indicator_code, {}).get("norm", "rank") == "minmax" else 2,
                        key=f"norm_{indicator_code}"
                    )
                
                with col4:
                    # ë°©í–¥ì„± ì„ íƒ
                    higher_better = st.checkbox(
                        "ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ",
                        value=default_indicators.get(indicator_code, {}).get("higher_is_better", True),
                        key=f"direction_{indicator_code}"
                    )
                
                selected_indicators[indicator_code] = {
                    "weight": weight,
                    "norm": norm_method,
                    "higher_is_better": higher_better
                }
                total_weight += weight
            else:
                # ì§€í‘œ ì„ íƒì´ ì·¨ì†Œëœ ê²½ìš° selected_indicatorsì—ì„œ ì œê±°
                if indicator_code in selected_indicators:
                    del selected_indicators[indicator_code]
            
            # session_state ì—…ë°ì´íŠ¸ (ì„ íƒ/ì·¨ì†Œ ëª¨ë‘ ë°˜ì˜)
            st.session_state.selected_indicators = selected_indicators



# ==============================
# ì‚¬ìš©ì ì •ì˜ ì§€í‘œ ì¶”ê°€
# ==============================
st.subheader("ì‚¬ìš©ì ì •ì˜ ì§€í‘œ ì¶”ê°€")

# ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ëª©ë¡ í‘œì‹œ
st.write("**ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼:**")
basic_columns = [
    'close', 'open', 'high', 'low', 'volume',
    'sma5', 'sma10', 'sma20', 'sma60', 'sma120',
    'ema12', 'ema26', 'rsi', 'macd', 'macd_signal', 'macd_histogram',
    'bb_upper', 'bb_middle', 'bb_lower', 'bb_width', 'bb_position',
    'volume_ratio', 'atr', 'volatility_20', 'volatility_60',
    'rel_mom_20', 'rel_mom_60', 'rel_mom_120',
    'high_52w_ratio', 'low_52w_ratio',
    'sharpe_ratio_20', 'sharpe_ratio_60', 'sortino_ratio_60', 'calmar_ratio_120',
    'return_2d', 'return_20d', 'return_60d'
]

additional_columns = st.session_state.get('all_columns', [])
all_columns = list(set(basic_columns + additional_columns))

st.code(", ".join(sorted(all_columns)))
st.write("ğŸ’¡ **íŒ**: ìœ„ ì»¬ëŸ¼ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì¡°ê±´ì‹ì„ ì‘ì„±í•˜ì„¸ìš”. ì˜ˆ: `volume / close`, `(close - sma20) / sma20 * 100`")

# ì¡°ê±´ì‹ ê²€ì¦ í•¨ìˆ˜
def validate_expression(expr, available_columns=None):
    """ì¡°ê±´ì‹ì´ ìœ íš¨í•œì§€ ê²€ì¦"""
    if not expr:
        return False, "ì¡°ê±´ì‹ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    try:
        # ê¸°ë³¸ ì»¬ëŸ¼ë“¤ (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
        basic_columns = [
            'close', 'open', 'high', 'low', 'volume',
            'sma5', 'sma10', 'sma20', 'sma60', 'sma120',
            'ema12', 'ema26', 'rsi', 'macd', 'macd_signal', 'macd_histogram',
            'bb_upper', 'bb_middle', 'bb_lower', 'bb_width', 'bb_position',
            'volume_ratio', 'atr', 'volatility_20', 'volatility_60',
            'rel_mom_20', 'rel_mom_60', 'rel_mom_120',
            'high_52w_ratio', 'low_52w_ratio',
            'sharpe_ratio_20', 'sharpe_ratio_60', 'sortino_ratio_60', 'calmar_ratio_120',
            'return_2d', 'return_20d', 'return_60d'
        ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ ëª©ë¡ (ê¸°ë³¸ + ì¶”ê°€)
        if available_columns:
            all_columns = list(set(basic_columns + available_columns))
        else:
            all_columns = basic_columns
        
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±
        test_data = {}
        for col in all_columns:
            test_data[col] = [1.0, 2.0, 3.0]  # í…ŒìŠ¤íŠ¸ìš© ê°’
        
        test_df = pd.DataFrame(test_data)
        
        # ì¡°ê±´ì‹ í‰ê°€ ì‹œë„
        result = pd.eval(expr, local_dict=test_df.to_dict(orient="series"))
        
        if len(result) == 3:  # ì˜ˆìƒëœ ê¸¸ì´
            return True, "âœ… ì¡°ê±´ì‹ì´ ìœ íš¨í•©ë‹ˆë‹¤."
        else:
            return False, "âŒ ì¡°ê±´ì‹ ê²°ê³¼ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤."
            
    except Exception as e:
        return False, f"âŒ ì¡°ê±´ì‹ ì˜¤ë¥˜: {str(e)}"

# ì‚¬ìš©ì ì •ì˜ ì§€í‘œ ì…ë ¥
custom_indicator_name = st.text_input("ì§€í‘œ ì´ë¦„", placeholder="ì˜ˆ: ê°€ê²©ëŒ€ë¹„ê±°ë˜ëŸ‰ë¹„ìœ¨", key="custom_indicator_name_1")
custom_indicator_expr = st.text_input("ì¡°ê±´ì‹", placeholder="ì˜ˆ: volume / close", key="custom_indicator_expr_1")

# ì¡°ê±´ì‹ ê²€ì¦ (í•­ìƒ ì‹¤í–‰)
if custom_indicator_expr:
    available_columns = st.session_state.get('all_columns', [])
    is_valid, validation_msg = validate_expression(custom_indicator_expr, available_columns)
    
    # ê²€ì¦ ê²°ê³¼ í‘œì‹œ
    if is_valid:
        st.success(validation_msg)
    else:
        st.error(validation_msg)
    
    if is_valid:
        # ì‚¬ìš©ì ì •ì˜ ì§€í‘œ ì„¤ì •
        col1, col2, col3, col4 = st.columns([2, 2, 2, 1])
        
        with col1:
            custom_weight = st.number_input(
                "ê°€ì¤‘ì¹˜",
                min_value=0.0,
                max_value=1.0,
                value=0.1,
                step=0.05,
                format="%.2f",
                key="custom_weight"
            )
        
        with col2:
            custom_norm = st.selectbox(
                "ì •ê·œí™” ë°©ë²•",
                options=["rank", "minmax", "zscore"],
                key="custom_norm"
            )
        
        with col3:
            custom_direction = st.checkbox(
                "ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ",
                value=True,
                key="custom_direction"
            )
        
        with col4:
            if st.button("ì§€í‘œ ì¶”ê°€", key="add_custom"):
                # ì‚¬ìš©ì ì •ì˜ ì§€í‘œë¥¼ selected_indicatorsì— ì¶”ê°€
                custom_key = f"custom_{custom_indicator_name}"
                selected_indicators[custom_key] = {
                    "weight": custom_weight,
                    "norm": custom_norm,
                    "higher_is_better": custom_direction,
                    "expression": custom_indicator_expr,  # ì‹¤ì œ ê³„ì‚°ì— ì‚¬ìš©í•  ì‹
                    "name": custom_indicator_name  # í‘œì‹œìš© ì´ë¦„
                }
                # session_state ì—…ë°ì´íŠ¸
                st.session_state.selected_indicators = selected_indicators
                st.success(f"'{custom_indicator_name}' ì§€í‘œê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()

# ì‚¬ìš©ì ì •ì˜ ì§€í‘œ ëª©ë¡ í‘œì‹œ
custom_indicators = {k: v for k, v in selected_indicators.items() if k.startswith('custom_')}
if custom_indicators:
    st.write("**ì¶”ê°€ëœ ì‚¬ìš©ì ì •ì˜ ì§€í‘œ:**")
    for key, config in custom_indicators.items():
        st.write(f"- {config['name']}: {config['expression']} (ê°€ì¤‘ì¹˜: {config['weight']:.2f})")

# ì „ì²´ ê°€ì¤‘ì¹˜ ì´í•© ì¬ê³„ì‚° (ê¸°ë³¸ ì§€í‘œ + ì‚¬ìš©ì ì •ì˜ ì§€í‘œ)
total_weight = sum(config.get("weight", 0) for config in selected_indicators.values())

# ê°€ì¤‘ì¹˜ ì´í•© í‘œì‹œ ë° ê²½ê³ 
st.write("---")
col1, col2 = st.columns(2)
with col1:
    st.metric("ì„ íƒëœ ì§€í‘œ ìˆ˜", len(selected_indicators))
with col2:
    st.metric("ê°€ì¤‘ì¹˜ ì´í•©", f"{total_weight:.2f}")
    
if abs(total_weight - 1.0) > 0.01:
    st.warning(f"âš ï¸ ê°€ì¤‘ì¹˜ ì´í•©ì´ 1.0ì´ ì•„ë‹™ë‹ˆë‹¤ ({total_weight:.2f}). ì •í™•í•œ ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•´ 1.0ìœ¼ë¡œ ë§ì¶°ì£¼ì„¸ìš”.")
else:
    st.success("âœ… ê°€ì¤‘ì¹˜ ì´í•©ì´ 1.0ì…ë‹ˆë‹¤.")

# ìë™ ê°€ì¤‘ì¹˜ ì¡°ì • ì˜µì…˜
if abs(total_weight - 1.0) > 0.01 and total_weight > 0:
    if st.button("ê°€ì¤‘ì¹˜ ìë™ ì¡°ì • (ì´í•©ì„ 1.0ìœ¼ë¡œ)"):
        for indicator in selected_indicators:
            selected_indicators[indicator]["weight"] /= total_weight
        # session_state ì—…ë°ì´íŠ¸
        st.session_state.selected_indicators = selected_indicators
        st.success("ê°€ì¤‘ì¹˜ê°€ ìë™ìœ¼ë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()

def calculate_custom_indicators(df, custom_indicators):
    """ì‚¬ìš©ì ì •ì˜ ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    result_df = df.copy()
    
    for indicator_key, config in custom_indicators.items():
        if 'expression' in config:
            try:
                # ì‚¬ìš©ì ì •ì˜ ì‹ ê³„ì‚°
                expr = config['expression']
                calculated_values = pd.eval(expr, local_dict=result_df.to_dict(orient="series"))
                result_df[indicator_key] = calculated_values
            except Exception as e:
                print(f"ì‚¬ìš©ì ì •ì˜ ì§€í‘œ '{config['name']}' ê³„ì‚° ì˜¤ë¥˜: {e}")
                result_df[indicator_key] = np.nan
    
    return result_df



# ==============================
# í•„í„° ë° íŠ¸ë¦¬ê±° ì„¤ì •
# ==============================
st.subheader("í•„í„° ë° íŠ¸ë¦¬ê±° ì„¤ì •")

# ê¸°ë³¸ ìŠ¤ì½”ì–´ë§ ì„¤ì • ì‚¬ìš©
scoring_config = ADVANCED_SCORE_CONFIG

# í•„í„° ì„¤ì •
st.write("**ğŸ“Š í•„í„° ì„¤ì • (AND ì¡°ê±´ - ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•¨)**")
st.write("ë¯¸í†µê³¼ ì‹œ ì´ì  ìƒí•œ(cap_if_fail)ì´ ì ìš©ë©ë‹ˆë‹¤.")

filter_exprs = []
col1, col2 = st.columns(2)

with col1:
    # ì¶”ì„¸ í•„í„°
    trend_filter = st.checkbox("ì¶”ì„¸ í•„í„°", value=True, help="sma20 > sma60 and close > sma20")
    if trend_filter:
        filter_exprs.append("sma20 > sma60 * 1.002 and close > sma20")
    
    # ì´ë™í‰ê·  ì •ë ¬ í•„í„°
    ma_alignment_filter = st.checkbox("ì´ë™í‰ê·  ì •ë ¬ í•„í„°", value=False, help="sma5 > sma20 and sma20 > sma60")
    if ma_alignment_filter:
        filter_exprs.append("sma5 > sma20 and sma20 > sma60")

with col2:
    # ê±°ë˜ëŸ‰ í•„í„°
    volume_filter = st.checkbox("ê±°ë˜ëŸ‰ í•„í„°", value=False, help="volume_ratio > 0.5")
    if volume_filter:
        filter_exprs.append("volume_ratio > 0.5")
    
    # RSI í•„í„°
    rsi_filter = st.checkbox("RSI í•„í„°", value=False, help="rsi >= 30 and rsi <= 70")
    if rsi_filter:
        filter_exprs.append("rsi >= 30 and rsi <= 70")

# í•„í„° ì‹¤íŒ¨ ì‹œ ìƒí•œê°’ ì„¤ì •
cap_if_fail = st.slider("í•„í„° ì‹¤íŒ¨ ì‹œ ì´ì  ìƒí•œ", min_value=0.0, max_value=100.0, value=40.0, step=5.0, help="í•„í„° ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•Šì„ ë•Œ ì ìš©ë  ìµœëŒ€ ì ìˆ˜")

# íŠ¸ë¦¬ê±° ì„¤ì •
st.write("**ğŸš€ íŠ¸ë¦¬ê±° ì„¤ì • (OR ì¡°ê±´ - í•˜ë‚˜ë¼ë„ ë§Œì¡±í•˜ë©´ ê°€ì‚°ì )**")

# íŠ¸ë¦¬ê±° ëª©ë¡
triggers = []

# ê³¨ë“ í¬ë¡œìŠ¤ íŠ¸ë¦¬ê±°
golden_cross = st.checkbox("ê³¨ë“ í¬ë¡œìŠ¤ íŠ¸ë¦¬ê±°", value=True, help="sma20ì´ sma60ì„ ìƒí–¥ëŒíŒŒí•  ë•Œ")
if golden_cross:
    golden_cross_score = st.number_input("ê³¨ë“ í¬ë¡œìŠ¤ ê°€ì‚°ì ", min_value=0.0, max_value=20.0, value=12.0, step=1.0)
    golden_cross_tau = st.number_input("ê³¨ë“ í¬ë¡œìŠ¤ ê°ì‡ ê¸°ê°„(tau)", min_value=1.0, max_value=20.0, value=5.0, step=1.0)
    triggers.append({
        "name": "Golden_20_60",
        "type": "event_decay",
        "event": "CROSSOVER(sma20, sma60)",
        "base": golden_cross_score,
        "tau": golden_cross_tau
    })

# MACD ì–‘ì „í™˜ íŠ¸ë¦¬ê±°
macd_turnup = st.checkbox("MACD ì–‘ì „í™˜ íŠ¸ë¦¬ê±°", value=True, help="MACD íˆìŠ¤í† ê·¸ë¨ì´ ìŒìˆ˜ì—ì„œ ì–‘ìˆ˜ë¡œ ì „í™˜í•  ë•Œ")
if macd_turnup:
    macd_score = st.number_input("MACD ì–‘ì „í™˜ ê°€ì‚°ì ", min_value=0.0, max_value=20.0, value=6.0, step=1.0)
    triggers.append({
        "name": "MACD_TurnUp",
        "type": "boolean",
        "expr": "macd_histogram > 0 and macd_histogram.shift(1) <= 0",
        "score": macd_score
    })

# ë³¼ë¦°ì € ë°´ë“œ ëŒíŒŒ íŠ¸ë¦¬ê±°
bb_breakout = st.checkbox("ë³¼ë¦°ì € ë°´ë“œ ìƒë‹¨ ëŒíŒŒ íŠ¸ë¦¬ê±°", value=False, help="closeê°€ bb_upperë¥¼ ìƒí–¥ëŒíŒŒí•  ë•Œ")
if bb_breakout:
    bb_score = st.number_input("ë³¼ë¦°ì € ë°´ë“œ ëŒíŒŒ ê°€ì‚°ì ", min_value=0.0, max_value=20.0, value=5.0, step=1.0)
    triggers.append({
        "name": "BB_Breakout",
        "type": "boolean",
        "expr": "close > bb_upper and close.shift(1) <= bb_upper.shift(1)",
        "score": bb_score
    })

# ê±°ë˜ëŸ‰ ê¸‰ì¦ íŠ¸ë¦¬ê±°
volume_surge = st.checkbox("ê±°ë˜ëŸ‰ ê¸‰ì¦ íŠ¸ë¦¬ê±°", value=True, help="ê±°ë˜ëŸ‰ì´ 20ì¼ í‰ê· ì˜ 1.5ë°° ì´ìƒì¼ ë•Œ")
if volume_surge:
    volume_surge_threshold = st.number_input("ê±°ë˜ëŸ‰ ê¸‰ì¦ ê¸°ì¤€", min_value=1.0, max_value=5.0, value=1.5, step=0.1)
    volume_surge_score = st.number_input("ê±°ë˜ëŸ‰ ê¸‰ì¦ ê°€ì‚°ì ", min_value=0.0, max_value=20.0, value=4.0, step=1.0)
    triggers.append({
        "name": "Volume_Surge",
        "type": "boolean",
        "expr": f"volume_ratio > {volume_surge_threshold}",
        "score": volume_surge_score
    })

# RSI ê³¼ë§¤ë„ ë°˜ë“± íŠ¸ë¦¬ê±°
rsi_bounce = st.checkbox("RSI ê³¼ë§¤ë„ ë°˜ë“± íŠ¸ë¦¬ê±°", value=False, help="RSIê°€ 30 ì´í•˜ì—ì„œ ë°˜ë“±í•  ë•Œ")
if rsi_bounce:
    rsi_bounce_score = st.number_input("RSI ë°˜ë“± ê°€ì‚°ì ", min_value=0.0, max_value=20.0, value=5.0, step=1.0)
    triggers.append({
        "name": "RSI_Bounce",
        "type": "boolean",
        "expr": "rsi < 30 and rsi > rsi.shift(1)",
        "score": rsi_bounce_score
    })

# ì„¤ì •ëœ í•„í„°ì™€ íŠ¸ë¦¬ê±°ë¥¼ ìŠ¤ì½”ì–´ë§ ì„¤ì •ì— ì ìš©
scoring_config["filters"]["exprs"] = filter_exprs
scoring_config["filters"]["cap_if_fail"] = cap_if_fail
scoring_config["rules"].extend(triggers)

# ì„¤ì • ìš”ì•½ í‘œì‹œ
st.write("**ğŸ“‹ ì„¤ì • ìš”ì•½**")
st.write(f"**í•„í„° ì¡°ê±´**: {len(filter_exprs)}ê°œ")
for i, expr in enumerate(filter_exprs, 1):
    st.write(f"{i}. {expr}")
st.write(f"**í•„í„° ì‹¤íŒ¨ ì‹œ ìƒí•œ**: {cap_if_fail:.1f}ì ")
st.write(f"**íŠ¸ë¦¬ê±° ì¡°ê±´**: {len(triggers)}ê°œ")
for trigger in triggers:
    st.write(f"- {trigger['name']}: {trigger.get('score', f'base={trigger.get('base', 0)}')}ì ")

# ==============================
# ë¶„ì„ ì‹¤í–‰
# ==============================
st.subheader("ë¶„ì„ ì‹¤í–‰")

# session_state ì´ˆê¸°í™”
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'analysis_completed' not in st.session_state:
    st.session_state.analysis_completed = False

if st.button("ë¶„ì„ ì‹œì‘") or st.session_state.analysis_completed:
    if not selected_codes:
        st.warning("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        # ì´ë¯¸ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆê³  ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¬ë¶„ì„í•˜ì§€ ì•ŠìŒ
        if st.session_state.analysis_completed and st.session_state.analysis_results is not None:
            st.write("**ì´ì „ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.**")
            all_results = st.session_state.analysis_results
        else:
            st.write("**ì„ íƒëœ ì¢…ëª©**:", selected_codes)
        
        # ì„ íƒëœ ê¸°ê°„ì˜ ê±°ë˜ì¼ë§Œ í•„í„°ë§
        selected_trading_dates = [d for d in filtered_trading_dates if start_date <= d <= end_date]
        st.write(f"**ë¶„ì„ ê¸°ê°„**: {len(selected_trading_dates)}ì¼")
        
        # KODEX 200 ë°ì´í„° ë¡œë“œ
        try:
            df_kodex = pd.read_csv(os.path.join(DATA_FOLDER, "069500_daily_price.csv"))
        except Exception as e:
            st.error(f"KODEX 200 ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.stop()
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        all_results = []
        
        # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
        st.write(f"**ë¶„ì„ ì‹œì‘**: {len(selected_codes)}ê°œ ì¢…ëª©, {len(selected_trading_dates)}ì¼")
        st.write(f"**ì„ íƒëœ ì¢…ëª©**: {selected_codes[:5]}{'...' if len(selected_codes) > 5 else ''}")
        st.write(f"**ë¶„ì„ ê¸°ê°„**: {selected_trading_dates[0]} ~ {selected_trading_dates[-1]}")
        
        for i, trading_date in enumerate(selected_trading_dates):
            status_text.text(f"ë¶„ì„ ì¤‘... {i+1}/{len(selected_trading_dates)}ì¼ì°¨ ({trading_date})")
            progress_bar.progress((i + 1) / len(selected_trading_dates))
            
            daily_results = []
            
            for code in selected_codes:
                try:
                    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                    file_path = os.path.join(DATA_FOLDER, f"{code}_daily_price.csv")
                    if not os.path.exists(file_path):
                        print(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                        continue
                        
                    df = pd.read_csv(file_path)
                    print(f"íŒŒì¼ ë¡œë“œ ì„±ê³µ: {code}, ë°ì´í„° í¬ê¸°: {df.shape}")
                    date_col = find_column(df, ['ê±°ë˜ì¼ì', 'date', 'Date', 'ë‚ ì§œ'])
                    close_col = find_column(df, ['ì¢…ê°€', 'close', 'Close'])
                    high_col = find_column(df, ['ê³ ê°€', 'high', 'High'])
                    low_col = find_column(df, ['ì €ê°€', 'low', 'Low'])
                    volume_col = find_column(df, ['ê±°ë˜ëŸ‰', 'volume', 'Volume'])
                    
                    # ì»¬ëŸ¼ ì°¾ê¸° ë””ë²„ê¹…
                    print(f"ì»¬ëŸ¼ ì°¾ê¸° ê²°ê³¼ - {code}: date={date_col}, close={close_col}, high={high_col}, low={low_col}, volume={volume_col}")
                    print(f"ì‹¤ì œ ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}")
                    
                    # YYYYMMDD í˜•ì‹ìœ¼ë¡œ íŒŒì‹±
                    df[date_col] = pd.to_datetime(df[date_col], format='%Y%m%d')
                    
                    # í•´ë‹¹ ë‚ ì§œê¹Œì§€ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
                    df_filtered = df[df[date_col] <= pd.to_datetime(trading_date)].copy()
                    
                    print(f"ë°ì´í„° í•„í„°ë§ - {code}: ì›ë³¸ {len(df)}í–‰ -> í•„í„°ë§ {len(df_filtered)}í–‰")
                    
                    if len(df_filtered) > 0:
                        # ìƒìŠ¹ë¥  ê³„ì‚°
                        df_filtered = calculate_returns(df_filtered, date_col, close_col)
                        
                        # ì´ë™í‰ê· ì„  ê³„ì‚°
                        df_filtered = calculate_sma(df_filtered, close_col)
                        df_filtered = calculate_ema(df_filtered, close_col)
                        
                        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                        df_filtered = calculate_rsi(df_filtered, close_col)
                        df_filtered = calculate_macd(df_filtered, close_col)
                        
                        # ê±°ë˜ëŸ‰ ì§€í‘œ ê³„ì‚°
                        if volume_col:
                            df_filtered = calculate_volume_indicators(df_filtered, volume_col, close_col)
                        
                        # ë³¼ë¦°ì € ë°´ë“œ ê³„ì‚°
                        df_filtered = calculate_bollinger_bands(df_filtered, close_col)
                        
                        # ATR ê³„ì‚°
                        if high_col and low_col:
                            df_filtered = calculate_atr(df_filtered, high_col, low_col, close_col)
                        
                        # ë³€ë™ì„± ì§€í‘œ ê³„ì‚°
                        df_filtered = calculate_volatility(df_filtered, close_col)
                        
                        # OHLC ê¸°ë°˜ ë³€ë™ì„± ê³„ì‚°
                        if high_col and low_col:
                            open_col = find_column(df_filtered, ['ì‹œê°€', 'open', 'Open'])
                            if open_col:
                                df_filtered = calculate_parkinson_volatility(df_filtered, high_col, low_col)
                                df_filtered = calculate_garman_klass_volatility(df_filtered, open_col, high_col, low_col, close_col)
                                df_filtered = calculate_true_range_volatility(df_filtered, high_col, low_col, close_col)
                        
                        # ìƒëŒ€ ëª¨ë©˜í…€ ê³„ì‚° (KODEX 200 ëŒ€ë¹„)
                        df_filtered = calculate_relative_momentum(df_filtered, df_kodex, date_col, close_col)
                        
                        # 52ì£¼ ê³ ì /ì €ì  ê³„ì‚°
                        if high_col and low_col:
                            df_filtered = calculate_52week_high_low(df_filtered, date_col, close_col, high_col, low_col)
                        
                        # ìœ„í—˜ì¡°ì •ìˆ˜ìµë¥  ì§€í‘œ ê³„ì‚°
                        df_filtered = calculate_sharpe_ratio(df_filtered, close_col)
                        df_filtered = calculate_sortino_ratio(df_filtered, close_col)
                        df_filtered = calculate_calmar_ratio(df_filtered, close_col)
                        
                        # ì‚¬ìš©ì ì •ì˜ ì§€í‘œ ê³„ì‚°
                        if custom_indicators:
                            df_filtered = calculate_custom_indicators(df_filtered, custom_indicators)
                        
                        # í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„° ì¶”ì¶œ
                        df_today = df_filtered[df_filtered[date_col] == pd.to_datetime(trading_date)]
                        
                        print(f"í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì¶”ì¶œ - {code}: {trading_date}, {len(df_today)}í–‰")
                        
                        # ì ìˆ˜ ê³„ì‚° ë¶€ë¶„ ìˆ˜ì • (ì „ì²´ ì¢…ëª© ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬)
                        if len(df_today) > 0:
                            row = df_today.iloc[0]
                            
                            # ì ìˆ˜ ê³„ì‚° (ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”)
                            score = None
                            try:
                                # í˜„ì¬ í–‰ì„ DataFrameìœ¼ë¡œ ë³€í™˜
                                df_score = pd.DataFrame([row])
                                
                                # ë””ë²„ê¹…: í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸
                                required_features = list(scoring_config.get("numeric", {}).keys())
                                available_features = [feat for feat in required_features if feat in df_score.columns]
                                missing_features = [feat for feat in required_features if feat not in df_score.columns]
                                
                                # ê° í”¼ì²˜ì˜ ê°’ í™•ì¸
                                print(f"\n=== Debug for {code} ===")
                                print(f"Available features: {available_features}")
                                print(f"Missing features: {missing_features}")
                                
                                for feat in required_features:
                                    if feat in df_score.columns:
                                        value = df_score[feat].iloc[0]
                                        print(f"{feat}: {value} (type: {type(value)})")
                                    else:
                                        print(f"{feat}: NOT FOUND")
                                
                                # ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ë§Œìœ¼ë¡œ ì„¤ì • ìˆ˜ì •
                                if available_features:
                                    # ë™ì ìœ¼ë¡œ ì„¤ì • ìƒì„±
                                    dynamic_config = {
                                        "numeric": {feat: scoring_config.get("numeric", {}).get(feat, {"weight": 0.1, "norm": "rank", "higher_is_better": True}) for feat in available_features},
                                        "rules": scoring_config.get("rules", []),
                                        "filters": scoring_config.get("filters", {})
                                    }
                                    
                                    # ì ìˆ˜ ê³„ì‚° (ì „ì²´ ì¢…ëª© ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •)
                                    score, contrib = score_frame_single_row(df_score, dynamic_config, all_results)
                                    
                                    if len(score) > 0:
                                        score = score.iloc[0]
                                        print(f"Score calculated for {code}: {score:.2f} (using features: {available_features})")
                                    else:
                                        print(f"No score calculated for {code} - empty result")
                                        score = None
                                else:
                                    print(f"No available features for {code}")
                                    score = None
                                    
                            except Exception as e:
                                print(f"Score calculation error for {code}: {e}")
                                import traceback
                                traceback.print_exc()
                                score = None
                            
                            result = {
                                'date': trading_date,
                                'code': code,
                                'name': CODE_TO_NAME.get(code, code),
                                'close': row[close_col],
                                'return_2d': row.get('return_2d', None),
                                'return_20d': row.get('return_20d', None),
                                'return_60d': row.get('return_60d', None),
                                'sma5': row.get('sma5', None),
                                'sma10': row.get('sma10', None),
                                'sma20': row.get('sma20', None),
                                'sma60': row.get('sma60', None),
                                'sma120': row.get('sma120', None),
                                'ema12': row.get('ema12', None),
                                'ema26': row.get('ema26', None),
                                'rsi': row.get('rsi', None),
                                'macd': row.get('macd', None),
                                'macd_signal': row.get('macd_signal', None),
                                'macd_histogram': row.get('macd_histogram', None),
                                'bb_upper': row.get('bb_upper', None),
                                'bb_middle': row.get('bb_middle', None),
                                'bb_lower': row.get('bb_lower', None),
                                'bb_width': row.get('bb_width', None),
                                'bb_position': row.get('bb_position', None),
                                'volume_sma5': row.get('volume_sma5', None),
                                'volume_sma20': row.get('volume_sma20', None),
                                'volume_ratio': row.get('volume_ratio', None),
                                'atr': row.get('atr', None),
                                'volatility_20': row.get('volatility_20', None),
                                'volatility_60': row.get('volatility_60', None),
                                'volatility_annualized_20': row.get('volatility_annualized_20', None),
                                'volatility_annualized_60': row.get('volatility_annualized_60', None),
                                'parkinson_volatility': row.get('parkinson_volatility', None),
                                'garman_klass_volatility': row.get('garman_klass_volatility', None),
                                'true_range_volatility': row.get('true_range_volatility', None),
                                'rel_mom_20': row.get('rel_mom_20', None),
                                'rel_mom_60': row.get('rel_mom_60', None),
                                'rel_mom_120': row.get('rel_mom_120', None),
                                'high_52w_ratio': row.get('high_52w_ratio', None),
                                'low_52w_ratio': row.get('low_52w_ratio', None),
                                'sharpe_ratio_20': row.get('sharpe_ratio_20', None),
                                'sharpe_ratio_60': row.get('sharpe_ratio_60', None),
                                'sharpe_ratio_120': row.get('sharpe_ratio_120', None),
                                'sortino_ratio_20': row.get('sortino_ratio_20', None),
                                'sortino_ratio_60': row.get('sortino_ratio_60', None),
                                'sortino_ratio_120': row.get('sortino_ratio_120', None),
                                'calmar_ratio_20': row.get('calmar_ratio_20', None),
                                'calmar_ratio_60': row.get('calmar_ratio_60', None),
                                'calmar_ratio_120': row.get('calmar_ratio_120', None),
                                'score': score
                            }
                            
                            daily_results.append(result)
                            print(f"ê²°ê³¼ ì¶”ê°€ ì™„ë£Œ - {code}: {trading_date}")
                            
                except Exception as e:
                    print(f"ì¢…ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {code}: {e}")
                    import traceback
                    traceback.print_exc()
                    continue
            
            all_results.extend(daily_results)
            print(f"ì¼ë³„ ê²°ê³¼ ì¶”ê°€ ì™„ë£Œ - {trading_date}: {len(daily_results)}ê°œ ì¢…ëª©")

            # ì§„í–‰ ìƒí™© ì™„ë£Œ
            progress_bar.empty()
            status_text.empty()
            
            # ê²°ê³¼ë¥¼ session_stateì— ì €ì¥
            st.session_state.analysis_results = all_results
            st.session_state.analysis_completed = True
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        if all_results:
            df_results = pd.DataFrame(all_results)
            st.session_state.analysis_results = df_results.to_dict('records')
            
            # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
            st.write(f"**ë¶„ì„ ì™„ë£Œ**: ì´ {len(all_results)}ê°œì˜ ê²°ê³¼ ìƒì„±")
            st.write(f"**ë°ì´í„°í”„ë ˆì„ í¬ê¸°**: {df_results.shape}")
            st.write(f"**ì»¬ëŸ¼ ëª©ë¡**: {list(df_results.columns)}")
            
            # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ
            st.subheader("ë¶„ì„ ê²°ê³¼")
            
            # ë‚ ì§œ ì„ íƒ
            unique_dates = sorted(df_results['date'].unique())
            selected_date = st.selectbox(
                "ë‚ ì§œ ì„ íƒ",
                options=unique_dates,
                format_func=lambda x: x.strftime('%Y-%m-%d'),
                index=len(unique_dates)-1  # ê¸°ë³¸ê°’ìœ¼ë¡œ ë§ˆì§€ë§‰ ë‚ ì§œ ì„ íƒ
            )
            
            # ì„ íƒëœ ë‚ ì§œì˜ ë°ì´í„°ë§Œ í•„í„°ë§
            df_selected = df_results[df_results['date'] == selected_date].copy()
            
            if len(df_selected) > 0:
                # ê²°ê³¼ í‘œì‹œ
                st.write(f"**{selected_date.strftime('%Yë…„ %mì›” %dì¼')} ë¶„ì„ ê²°ê³¼**")
                
                # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì • (ì ìˆ˜ ì¶”ê°€)
                display_columns = [
                    'name', 'close', 'score',
                    'return_2d', 'return_20d', 'return_60d',
                    'sma5', 'sma10', 'sma20', 'sma60', 'sma120',
                    'ema12', 'ema26', 'rsi', 'macd', 'macd_signal', 'macd_histogram',
                    'bb_upper', 'bb_middle', 'bb_lower', 'bb_width', 'bb_position',
                    'volume_sma5', 'volume_sma20', 'volume_ratio', 'atr',
                    'volatility_20', 'volatility_60', 'volatility_annualized_20', 'volatility_annualized_60',
                    'parkinson_volatility', 'garman_klass_volatility', 'true_range_volatility',
                    'rel_mom_20', 'rel_mom_60', 'rel_mom_120',
                    'high_52w_ratio', 'low_52w_ratio',
                    'sharpe_ratio_20', 'sharpe_ratio_60', 'sharpe_ratio_120',
                    'sortino_ratio_20', 'sortino_ratio_60', 'sortino_ratio_120',
                    'calmar_ratio_20', 'calmar_ratio_60', 'calmar_ratio_120'
                ]
                
                # ì»¬ëŸ¼ëª… í•œê¸€ë¡œ ë³€ê²½ (ì ìˆ˜ ì¶”ê°€)
                column_mapping = {
                    'name': 'ì¢…ëª©ëª…',
                    'close': 'ì¢…ê°€',
                    'score': 'ì¢…í•©ì ìˆ˜',
                    'return_2d': '2ì¼ ìƒìŠ¹ë¥ (%)',
                    'return_20d': '20ì¼ ìƒìŠ¹ë¥ (%)',
                    'return_60d': '60ì¼ ìƒìŠ¹ë¥ (%)',
                    'sma5': 'SMA5',
                    'sma10': 'SMA10',
                    'sma20': 'SMA20',
                    'sma60': 'SMA60',
                    'sma120': 'SMA120',
                    'ema12': 'EMA12',
                    'ema26': 'EMA26',
                    'rsi': 'RSI',
                    'macd': 'MACD',
                    'macd_signal': 'MACD Signal',
                    'macd_histogram': 'MACD Histogram',
                    'bb_upper': 'BB Upper',
                    'bb_middle': 'BB Middle',
                    'bb_lower': 'BB Lower',
                    'bb_width': 'BB Width(%)',
                    'bb_position': 'BB Position(%)',
                    'volume_sma5': 'Volume SMA5',
                    'volume_sma20': 'Volume SMA20',
                    'volume_ratio': 'Volume Ratio',
                    'atr': 'ATR',
                    'volatility_20': 'ë³€ë™ì„± 20ì¼(%)',
                    'volatility_60': 'ë³€ë™ì„± 60ì¼(%)',
                    'volatility_annualized_20': 'ì—°ìœ¨ë³€ë™ì„± 20ì¼(%)',
                    'volatility_annualized_60': 'ì—°ìœ¨ë³€ë™ì„± 60ì¼(%)',
                    'parkinson_volatility': 'Parkinson ë³€ë™ì„±(%)',
                    'garman_klass_volatility': 'Garman-Klass ë³€ë™ì„±(%)',
                    'true_range_volatility': 'True Range ë³€ë™ì„±(%)',
                    'rel_mom_20': '20ì¼ ìƒëŒ€ëª¨ë©˜í…€(%)',
                    'rel_mom_60': '60ì¼ ìƒëŒ€ëª¨ë©˜í…€(%)',
                    'rel_mom_120': '120ì¼ ìƒëŒ€ëª¨ë©˜í…€(%)',
                    'high_52w_ratio': '52ì£¼ê³ ì ë¹„ìœ¨(%)',
                    'low_52w_ratio': '52ì£¼ì €ì ë¹„ìœ¨(%)',
                    'sharpe_ratio_20': 'Sharpe ì§€ìˆ˜ 20ì¼',
                    'sharpe_ratio_60': 'Sharpe ì§€ìˆ˜ 60ì¼',
                    'sharpe_ratio_120': 'Sharpe ì§€ìˆ˜ 120ì¼',
                    'sortino_ratio_20': 'Sortino ì§€ìˆ˜ 20ì¼',
                    'sortino_ratio_60': 'Sortino ì§€ìˆ˜ 60ì¼',
                    'sortino_ratio_120': 'Sortino ì§€ìˆ˜ 120ì¼',
                    'calmar_ratio_20': 'Calmar ì§€ìˆ˜ 20ì¼',
                    'calmar_ratio_60': 'Calmar ì§€ìˆ˜ 60ì¼',
                    'calmar_ratio_120': 'Calmar ì§€ìˆ˜ 120ì¼'
                }
                
                df_display = df_selected[display_columns].copy()
                df_display.columns = [column_mapping[col] for col in display_columns]
                
                # ì†Œìˆ˜ì  ìë¦¬ìˆ˜ ì¡°ì •
                numeric_columns = [col for col in df_display.columns if col != 'ì¢…ëª©ëª…']
                df_display[numeric_columns] = df_display[numeric_columns].round(2)
                
                # ì¢…ê°€ë¥¼ ì •ìˆ˜ë¡œ í‘œì‹œ
                df_display['ì¢…ê°€'] = df_display['ì¢…ê°€'].astype(int)
                
                st.dataframe(df_display, use_container_width=True)
                
                # ì „ì²´ ê¸°ê°„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.subheader("ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
                csv_data = df_results.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name=f"stock_analysis_{start_date}_{end_date}.csv",
                    mime="text/csv"
                )
                
            else:
                st.warning("ì„ íƒëœ ë‚ ì§œì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")



# ==============================
# ê¸°ë³¸ ì„±ëŠ¥ ê²€ì¦: ì ìˆ˜ êµ¬ê°„ë³„ ë‹¤ìŒë‚  ìˆ˜ìµë¥ 
# ==============================
def _render_score_bin_eval():
    st.subheader("ì ìˆ˜ êµ¬ê°„ë³„ ìˆ˜ìµë¥  ë¹„êµ ë¶„ì„")

    # Try to find results
    df_results = None
    if 'df_results' in globals():
        try:
            if isinstance(globals()['df_results'], (pd.DataFrame, pd.core.frame.DataFrame)):
                df_results = globals()['df_results']
        except Exception:
            pass
    if df_results is None:
        # Try from session_state
        try:
            if st.session_state.get('analysis_results') is not None:
                df_results = pd.DataFrame(st.session_state.analysis_results)
        except Exception:
            df_results = None

    if df_results is None or df_results.empty or 'score' not in df_results.columns or 'close' not in df_results.columns:
        st.info("ê²€ì¦ì„ ìœ„í•œ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í•„ìˆ˜ ì»¬ëŸ¼: score, close, date, code)")
        return

    df_eval = df_results.copy()
    # Ensure required columns exist
    required_cols = {'date','code','close','score'}
    missing = required_cols - set(map(str.lower, df_eval.columns))
    # Try to normalize column names to lower-case if needed
    df_eval.columns = [c.lower() for c in df_eval.columns]
    required_cols = {'date','code','close','score'}
    if not required_cols.issubset(df_eval.columns):
        st.warning(f"ê²€ì¦ ë¶ˆê°€ - í•„ìš”í•œ ì»¬ëŸ¼ ëˆ„ë½: {required_cols - set(df_eval.columns)}")
        return

    # Prepare
    df_eval['date'] = pd.to_datetime(df_eval['date'])
    df_eval = df_eval.sort_values(['code','date'])
    
    # ì—¬ëŸ¬ ê¸°ê°„ì˜ ìˆ˜ìµë¥  ê³„ì‚°
    df_eval['close_next_1d'] = df_eval.groupby('code')['close'].shift(-1)
    df_eval['close_next_3d'] = df_eval.groupby('code')['close'].shift(-3)
    df_eval['close_next_5d'] = df_eval.groupby('code')['close'].shift(-5)
    df_eval['close_next_20d'] = df_eval.groupby('code')['close'].shift(-20)
    
    df_eval['ret_next_1d'] = (df_eval['close_next_1d'] / df_eval['close'] - 1.0) * 100.0
    df_eval['ret_next_3d'] = (df_eval['close_next_3d'] / df_eval['close'] - 1.0) * 100.0
    df_eval['ret_next_5d'] = (df_eval['close_next_5d'] / df_eval['close'] - 1.0) * 100.0
    df_eval['ret_next_20d'] = (df_eval['close_next_20d'] / df_eval['close'] - 1.0) * 100.0

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df_eval = df_eval.replace([np.inf, -np.inf], np.nan).dropna(subset=['score','ret_next_1d'])

    q = st.slider("ë¶„ìœ„ìˆ˜ êµ¬ê°„ ìˆ˜(q)", min_value=3, max_value=10, value=5, step=1, key="q_bins_score_eval")
    try:
        df_eval['score_bin'] = pd.qcut(df_eval['score'], q=q, labels=[f"Q{i}" for i in range(1, q+1)])
    except Exception:
        st.warning("ìŠ¤ì½”ì–´ ë¶„í¬ê°€ ì¹˜ìš°ì³ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„ ë§Œë“¤ê¸° ì–´ë µìŠµë‹ˆë‹¤. q ê°’ì„ ì¤„ì—¬ë³´ì„¸ìš”.")
        df_eval['score_bin'] = pd.qcut(df_eval['score'], q=3, labels=["Q1","Q2","Q3"])
        q = 3

    # ê° ê¸°ê°„ë³„ ì„±ê³¼ ë¶„ì„
    periods = [
        ('ret_next_1d', 'ë‹¤ìŒë‚ '),
        ('ret_next_3d', '3ì¼ ë’¤'),
        ('ret_next_5d', '5ê±°ë˜ì¼ ë’¤'),
        ('ret_next_20d', '20ê±°ë˜ì¼ ë’¤')
    ]
    
    for ret_col, period_name in periods:
        st.write(f"**{period_name} ìˆ˜ìµë¥  ë¶„ì„**")
        
        bin_perf = (df_eval.groupby('score_bin')
                    .agg(mean_ret=(ret_col,'mean'),
                         median_ret=(ret_col,'median'),
                         win_rate=(ret_col, lambda x: np.mean(x > 0) * 100.0),
                         count=(ret_col,'size'),
                         mean_score=('score','mean'))
                    .reset_index()
                    .sort_values('score_bin'))

        try:
            st.dataframe(bin_perf.style.format({
                'mean_ret': '{:.3f}%',
                'median_ret': '{:.3f}%',
                'win_rate': '{:.1f}%',
                'mean_score': '{:.2f}'
            }), use_container_width=True)
        except Exception:
            st.dataframe(bin_perf, use_container_width=True)

        # Top - Bottom spread
        top_label, bottom_label = f"Q{q}", "Q1"
        try:
            top_val = bin_perf.loc[bin_perf['score_bin'].astype(str)==top_label, 'mean_ret'].values[0]
            bot_val = bin_perf.loc[bin_perf['score_bin'].astype(str)==bottom_label, 'mean_ret'].values[0]
            spread = top_val - bot_val
            st.metric(f"{top_label} - {bottom_label} í‰ê·  {period_name} ìˆ˜ìµë¥  ì°¨ì´", f"{spread:.3f}%")
        except Exception:
            pass
        
        st.write("---")

    # Daily IC (Spearman) - scipy ì—†ì´ ê³„ì‚°
    st.write("**IC (Information Coefficient) ë¶„ì„**")
    try:
        # ë” ì•ˆì „í•œ IC ê³„ì‚° ë°©ë²• (scipy ì—†ì´)
        daily_ic_list = []
        total_dates = 0
        
        for date in df_eval['date'].unique():
            total_dates += 1
            date_data = df_eval[df_eval['date'] == date]
            
            if len(date_data) > 1:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ ë°ì´í„°ê°€ ìˆì–´ì•¼ ìƒê´€ê´€ê³„ ê³„ì‚° ê°€ëŠ¥
                try:
                    # ì•ˆì „í•œ Spearman ìƒê´€ê´€ê³„ ê³„ì‚°
                    ic = safe_spearman_corr(date_data['score'], date_data['ret_next_1d'])
                    if not pd.isna(ic) and abs(ic) <= 1.0:  # ìœ íš¨í•œ ìƒê´€ê´€ê³„ ê°’ì¸ì§€ í™•ì¸
                        daily_ic_list.append(ic)
                except Exception as e:
                    print(f"IC ê³„ì‚° ì˜¤ë¥˜ (ë‚ ì§œ: {date}): {e}")
                    continue
        
        if daily_ic_list:
            daily_ic = pd.Series(daily_ic_list)
            st.metric("ì¼ë³„ í‰ê·  IC (Spearman)", f"{daily_ic.mean():.3f}")
            st.write(f"IC í‘œì¤€í¸ì°¨: {daily_ic.std():.3f}, ê´€ì¸¡ì¹˜ ìˆ˜: {len(daily_ic)}")
            st.write(f"ì „ì²´ ë‚ ì§œ ìˆ˜: {total_dates}, IC ê³„ì‚° ì„±ê³µ: {len(daily_ic_list)}")
        else:
            st.warning("IC ê³„ì‚°ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.write(f"ì „ì²´ ë‚ ì§œ ìˆ˜: {total_dates}, IC ê³„ì‚° ì„±ê³µ: 0")
    except Exception as e:
        st.warning(f"IC ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        st.write(f"ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
        import traceback
        st.code(traceback.format_exc())

    # ë¶„ì„ ê²°ê³¼ ì„¤ëª…
    st.write("---")
    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ í•´ì„ ê°€ì´ë“œ")
    
    st.write("""
    ### ğŸ” **ì ìˆ˜ êµ¬ê°„ë³„ ìˆ˜ìµë¥  ë¹„êµ ë¶„ì„**
    
    **ë¶„ìœ„ìˆ˜(Q) êµ¬ë¶„:**
    - **Q1**: ê°€ì¥ ë‚®ì€ ì ìˆ˜ êµ¬ê°„ (0-20% ë˜ëŠ” 0-25%)
    - **Q2~Q4**: ì¤‘ê°„ ì ìˆ˜ êµ¬ê°„ë“¤
    - **Q5**: ê°€ì¥ ë†’ì€ ì ìˆ˜ êµ¬ê°„ (80-100% ë˜ëŠ” 75-100%)
    
    **ì§€í‘œ í•´ì„:**
    - **í‰ê·  ìˆ˜ìµë¥ **: í•´ë‹¹ êµ¬ê°„ì˜ í‰ê·  ìˆ˜ìµë¥ 
    - **ì¤‘ê°„ê°’ ìˆ˜ìµë¥ **: ì¤‘ê°„ê°’ ê¸°ì¤€ ìˆ˜ìµë¥  (ê·¹ë‹¨ê°’ ì˜í–¥ ì ìŒ)
    - **ìŠ¹ë¥ **: ì–‘ìˆ˜ ìˆ˜ìµë¥ ì„ ê¸°ë¡í•œ ë¹„ìœ¨
    - **í‰ê·  ì ìˆ˜**: í•´ë‹¹ êµ¬ê°„ì˜ í‰ê·  ìŠ¤ì½”ì–´ë§ ì ìˆ˜
    
    **ì„±ê³¼ í‰ê°€:**
    - **Q5 - Q1 ì°¨ì´**: ë†’ì€ ì ìˆ˜ êµ¬ê°„ê³¼ ë‚®ì€ ì ìˆ˜ êµ¬ê°„ì˜ ìˆ˜ìµë¥  ì°¨ì´
    - **ì–‘ìˆ˜ ì°¨ì´**: ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œì´ ìœ íš¨í•¨ì„ ì˜ë¯¸
    - **ì°¨ì´ê°€ í´ìˆ˜ë¡**: ë” ê°•ë ¥í•œ ì˜ˆì¸¡ë ¥ì„ ê°€ì§
    
    ### ğŸ“ˆ **IC (Information Coefficient) ë¶„ì„**
    
    **ICë€?**
    - ì ìˆ˜ì™€ ì‹¤ì œ ìˆ˜ìµë¥  ê°„ì˜ ìˆœìœ„ ìƒê´€ê´€ê³„
    - -1 ~ +1 ë²”ìœ„ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì˜ˆì¸¡ë ¥ ì—†ìŒ)
    - **ì–‘ìˆ˜**: ë†’ì€ ì ìˆ˜ â†’ ë†’ì€ ìˆ˜ìµë¥  (ì •ìƒ)
    - **ìŒìˆ˜**: ë†’ì€ ì ìˆ˜ â†’ ë‚®ì€ ìˆ˜ìµë¥  (ì—­ë°©í–¥)
    
    **IC í•´ì„ ê¸°ì¤€:**
    - **0.05 ì´ìƒ**: ì¢‹ì€ ì˜ˆì¸¡ë ¥
    - **0.10 ì´ìƒ**: ë§¤ìš° ì¢‹ì€ ì˜ˆì¸¡ë ¥
    - **0.15 ì´ìƒ**: íƒì›”í•œ ì˜ˆì¸¡ë ¥
    
    **IC í‘œì¤€í¸ì°¨:**
    - ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì ì¸ ì˜ˆì¸¡ë ¥
    - ë†’ì„ìˆ˜ë¡ ë³€ë™ì„±ì´ í° ì˜ˆì¸¡ë ¥
    
    ### ğŸ¯ **íˆ¬ì ì „ëµ í™œìš©**
    
    **ë‹¨ê¸° ì „ëµ (1-3ì¼):**
    - ë†’ì€ ICì™€ í° Q5-Q1 ì°¨ì´ í™•ì¸
    - ë‹¨ê¸° ëª¨ë©˜í…€ í™œìš©
    
    **ì¤‘ê¸° ì „ëµ (5-20ì¼):**
    - ì§€ì†ì ì¸ ì˜ˆì¸¡ë ¥ í™•ì¸
    - í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸° ê²°ì •
    
    **ë¦¬ìŠ¤í¬ ê´€ë¦¬:**
    - IC í‘œì¤€í¸ì°¨ê°€ ë†’ìœ¼ë©´ ë³´ìˆ˜ì  ì ‘ê·¼
    - ìŠ¹ë¥ ê³¼ í•¨ê»˜ ì¢…í•© íŒë‹¨
    """)

# ìë™ ë Œë”: í˜ì´ì§€ í•˜ë‹¨ì—ì„œ í•œ ë²ˆ í˜¸ì¶œ
try:
    _render_score_bin_eval()
except Exception:
    # If Streamlit context not ready, ignore
    pass